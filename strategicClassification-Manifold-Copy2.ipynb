{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import cvxpy as cp\n",
    "import dccp\n",
    "import torch\n",
    "import numpy as np\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import zero_one_loss, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.patches as mpatches\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import os, psutil\n",
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd.functional import jacobian\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "TRAIN_SLOPE = 2\n",
    "EVAL_SLOPE = 5\n",
    "X_LOWER_BOUND = -10\n",
    "X_UPPER_BOUND = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, Y, percentage):\n",
    "    num_val = int(len(X)*percentage)\n",
    "    return X[num_val:], Y[num_val:], X[:num_val], Y[:num_val]\n",
    "\n",
    "def shuffle(X, Y):\n",
    "    data = torch.cat((X, Y), 1)\n",
    "    data = data[torch.randperm(data.size()[0])]\n",
    "    X = data[:, :2]\n",
    "    Y = data[:, 2]\n",
    "    return X, Y\n",
    "\n",
    "def conf_mat(Y1, Y2):\n",
    "    num_of_samples = len(Y1)\n",
    "    mat = confusion_matrix(Y1, Y2, labels=[-1, 1])*100/num_of_samples\n",
    "    acc = np.trace(mat)\n",
    "    return mat, acc\n",
    "\n",
    "def calc_accuracy(Y, Ypred):\n",
    "    num = len(Y)\n",
    "    temp = Y - Ypred\n",
    "    acc = len(temp[temp == 0])*1./num\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spam_data():\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    path = r\"C:\\Users\\sagil\\Desktop\\nir_project\\tip_spam_data\\IS_journal_tip_spam.arff\"\n",
    "    data, meta = arff.loadarff(path)\n",
    "    df = pd.DataFrame(data)\n",
    "    most_disc = ['qTips_plc', 'rating_plc', 'qEmail_tip', 'qContacts_tip', 'qURL_tip', 'qPhone_tip', 'qNumeriChar_tip', 'sentistrength_tip', 'combined_tip', 'qWords_tip', 'followers_followees_gph', 'qunigram_avg_tip', 'qTips_usr', 'indeg_gph', 'qCapitalChar_tip', 'class1']\n",
    "    df = df[most_disc]\n",
    "    df[\"class1\"].replace({b'spam': -1, b'notspam': 1}, inplace=True)\n",
    "    df = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "    Y = df['class1'].values\n",
    "    X = df.drop('class1', axis = 1).values\n",
    "    x_dim = len(X[0])\n",
    "    X -= np.mean(X, axis=0)\n",
    "    X /= np.std(X, axis=0)\n",
    "    X /= math.sqrt(x_dim)\n",
    "    return torch.from_numpy(X), torch.from_numpy(Y)\n",
    "\n",
    "def load_card_fraud_data():\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    df = pd.read_csv('C:/Users/sagil/Desktop/nir_project/card_fraud_dataset/creditcard.csv')\n",
    "\n",
    "    rob_scaler = RobustScaler()\n",
    "\n",
    "    df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "    df.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "    scaled_amount = df['scaled_amount']\n",
    "    df.drop(['scaled_amount'], axis=1, inplace=True)\n",
    "    df.insert(0, 'scaled_amount', scaled_amount)\n",
    "\n",
    "    df[\"Class\"].replace({1: -1, 0: 1}, inplace=True)\n",
    "    df = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "    # amount of fraud classes 492 rows.\n",
    "    fraud_df = df.loc[df['Class'] == -1]\n",
    "    non_fraud_df = df.loc[df['Class'] == 1][:492]\n",
    "\n",
    "    normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "    # Shuffle dataframe rows\n",
    "    df = normal_distributed_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "    Y = df['Class'].values\n",
    "    X = df.drop('Class', axis = 1).values\n",
    "    x_dim = len(X[0])\n",
    "    X -= np.mean(X, axis=0)\n",
    "    X /= np.std(X, axis=0)\n",
    "    X /= math.sqrt(x_dim)\n",
    "    return torch.from_numpy(X), torch.from_numpy(Y)\n",
    "\n",
    "def load_credit_default_data():\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    url = 'https://raw.githubusercontent.com/ustunb/actionable-recourse/master/examples/paper/data/credit_processed.csv'\n",
    "    df = pd.read_csv(url)\n",
    "    df[\"NoDefaultNextMonth\"].replace({0: -1}, inplace=True)\n",
    "    df = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "    df = df.drop(['Married', 'Single', 'Age_lt_25', 'Age_in_25_to_40', 'Age_in_40_to_59', 'Age_geq_60'], axis = 1)\n",
    "\n",
    "    fraud_df = df.loc[df[\"NoDefaultNextMonth\"] == -1]\n",
    "    non_fraud_df = df.loc[df[\"NoDefaultNextMonth\"] == 1][:6636]\n",
    "\n",
    "    normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "    # Shuffle dataframe rows\n",
    "    df = normal_distributed_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    df.loc[:, df.columns != \"NoDefaultNextMonth\"] = scaler.fit_transform(df.drop(\"NoDefaultNextMonth\", axis=1)) \n",
    "    Y, X = df.iloc[:, 0].values, df.iloc[:, 1:].values\n",
    "    x_dim = len(X[0])\n",
    "    X -= np.mean(X, axis=0)\n",
    "    X /= np.std(X, axis=0)\n",
    "    X /= math.sqrt(x_dim)\n",
    "    return torch.from_numpy(X), torch.from_numpy(Y)\n",
    "\n",
    "def load_financial_distress_data():\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    data = pd.read_csv(\"C:/Users/sagil/Desktop/nir_project/financial_distress_data/Financial Distress.csv\")\n",
    "\n",
    "    data = data[data.columns.drop(list(data.filter(regex='x80')))] # Since it is a categorical feature with 37 features.\n",
    "    x_dim = len(data.columns) - 3\n",
    "    data.drop(['Time'], axis=1, inplace=True)\n",
    "\n",
    "    data_grouped = data.groupby(['Company']).last()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    data_grouped.loc[:, data_grouped.columns != \"Financial Distress\"] = scaler.fit_transform(data_grouped.drop(\"Financial Distress\", axis=1))\n",
    "\n",
    "    # Shuffle dataframe rows\n",
    "    data_grouped = data_grouped.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "    Y, X = data_grouped.iloc[:, 0].values, data_grouped.iloc[:, 1:].values\n",
    "    for y in range(0,len(Y)): # Coverting target variable from continuous to binary form\n",
    "        if Y[y] < -0.5:\n",
    "              Y[y] = -1\n",
    "        else:\n",
    "              Y[y] = 1\n",
    "    x_dim = len(X[0])\n",
    "    X -= np.mean(X, axis=0)\n",
    "    X /= np.std(X, axis=0)\n",
    "    X /= math.sqrt(x_dim)\n",
    "    return torch.from_numpy(X), torch.from_numpy(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCP classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCP:\n",
    "    def __init__(self, x_dim, h_dim, funcs):\n",
    "        self.f_derivative = funcs[\"f_derivative\"]\n",
    "        self.g = funcs[\"g\"]\n",
    "        self.c = funcs[\"c\"]\n",
    "        \n",
    "        self.x = cp.Variable(x_dim)\n",
    "        self.xt = cp.Parameter(x_dim)\n",
    "        self.r = cp.Parameter(x_dim)\n",
    "        self.w = cp.Parameter(x_dim)\n",
    "        self.b = cp.Parameter(1)\n",
    "        self.slope = cp.Parameter(1)\n",
    "        \n",
    "\n",
    "        target = self.x@self.f_derivative(self.xt, self.w, self.b, self.slope)-self.g(self.x, self.w, self.b, self.slope)-self.c(self.x, self.r, x_dim)\n",
    "        constraints = [self.x >= X_LOWER_BOUND,\n",
    "                       self.x <= X_UPPER_BOUND]\n",
    "        self.prob = cp.Problem(cp.Maximize(target), constraints)\n",
    "        \n",
    "    def ccp(self, r):\n",
    "        \"\"\"\n",
    "        numpy to numpy\n",
    "        \"\"\"\n",
    "        self.xt.value = r\n",
    "        self.r.value = r\n",
    "        result = self.prob.solve()\n",
    "        diff = np.linalg.norm(self.xt.value - self.x.value)\n",
    "        cnt = 0\n",
    "        while diff > 0.0001 and cnt < 10:\n",
    "            cnt += 1\n",
    "            self.xt.value = self.x.value\n",
    "            result = self.prob.solve()\n",
    "            diff = np.linalg.norm(self.x.value - self.xt.value)\n",
    "        return self.x.value\n",
    "    \n",
    "    def optimize_X(self, X, w, b, B_SPAN, slope):\n",
    "        \"\"\"\n",
    "        tensor to tensor\n",
    "        \"\"\"\n",
    "        X = X.numpy()\n",
    "        w = w.detach().numpy()\n",
    "        b = b.detach().numpy()\n",
    "        slope = np.full(1, slope)\n",
    "        \n",
    "        self.w.value = w\n",
    "        self.b.value = b\n",
    "        self.slope.value = slope\n",
    "        \n",
    "        return torch.stack([torch.from_numpy(self.ccp(x)) for x in X])\n",
    "    \n",
    "    \n",
    "class CCP_MANIFOLD:\n",
    "    def __init__(self, x_dim, h_dim, funcs):\n",
    "        self.f_derivative = funcs[\"f_derivative\"]\n",
    "        self.g = funcs[\"g\"]\n",
    "        self.c = funcs[\"c\"]\n",
    "        \n",
    "        self.x = cp.Variable(x_dim)\n",
    "        self.v = cp.Variable(h_dim)\n",
    "        self.xt = cp.Parameter(x_dim)\n",
    "        self.r = cp.Parameter(x_dim)\n",
    "        self.w = cp.Parameter(x_dim)\n",
    "        self.b = cp.Parameter(1)\n",
    "        self.B_span = cp.Parameter((x_dim, h_dim))\n",
    "        self.slope = cp.Parameter(1)\n",
    "        \n",
    "\n",
    "        target = self.x@self.f_derivative(self.xt, self.w, self.b, self.slope)-self.g(self.x, self.w, self.b, self.slope)-self.c(self.x, self.r, x_dim)\n",
    "        constraints = [self.x >= X_LOWER_BOUND,\n",
    "                       self.x <= X_UPPER_BOUND,\n",
    "                      self.B_span@self.v == self.x-self.r]\n",
    "        self.prob = cp.Problem(cp.Maximize(target), constraints)\n",
    "        \n",
    "    def ccp(self, r, B_span):\n",
    "        \"\"\"\n",
    "        numpy to numpy\n",
    "        \"\"\"\n",
    "        self.xt.value = r\n",
    "        self.r.value = r\n",
    "        self.B_span.value = B_span\n",
    "        result = self.prob.solve()\n",
    "        diff = np.linalg.norm(self.xt.value - self.x.value)\n",
    "        cnt = 0\n",
    "        while diff > 0.0001 and cnt < 10:\n",
    "            cnt += 1\n",
    "            self.xt.value = self.x.value\n",
    "            result = self.prob.solve()\n",
    "            diff = np.linalg.norm(self.x.value - self.xt.value)\n",
    "        return self.x.value\n",
    "    \n",
    "    def optimize_X(self, X, w, b, B_SPAN, slope):\n",
    "        \"\"\"\n",
    "        tensor to tensor\n",
    "        \"\"\"\n",
    "        X = X.numpy()\n",
    "        w = w.detach().numpy()\n",
    "        b = b.detach().numpy()\n",
    "        B_SPAN = B_SPAN.numpy()\n",
    "        slope = np.full(1, slope)\n",
    "        \n",
    "        self.w.value = w\n",
    "        self.b.value = b\n",
    "        self.slope.value = slope\n",
    "        \n",
    "        return torch.stack([torch.from_numpy(self.ccp(x, B_span)) for x, B_span in zip(X, B_SPAN)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DELTA():\n",
    "    \n",
    "    def __init__(self, x_dim, h_dim, funcs):\n",
    "        self.g = funcs[\"g\"]\n",
    "        self.c = funcs[\"c\"]\n",
    "        \n",
    "        self.x = cp.Variable(x_dim)\n",
    "        self.r = cp.Parameter(x_dim, value = np.random.randn(x_dim))\n",
    "        self.w = cp.Parameter(x_dim, value = np.random.randn(x_dim))\n",
    "        self.b = cp.Parameter(1, value = np.random.randn(1))\n",
    "        self.f_der = cp.Parameter(x_dim, value = np.random.randn(x_dim))\n",
    "\n",
    "        target = self.x@self.f_der-self.g(self.x, self.w, self.b, TRAIN_SLOPE)-self.c(self.x, self.r, x_dim)\n",
    "        constraints = [self.x >= X_LOWER_BOUND,\n",
    "                       self.x <= X_UPPER_BOUND]\n",
    "        objective = cp.Maximize(target)\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        self.layer = CvxpyLayer(problem, parameters=[self.r, self.w, self.b, self.f_der],\n",
    "                                variables=[self.x])\n",
    "        \n",
    "        \n",
    "    def optimize_X(self, X, w, b, F_DER, B_SPAN):\n",
    "        return self.layer(X, w, b, F_DER)[0]\n",
    "    \n",
    "class DELTA_MANIFOLD():\n",
    "    \n",
    "    def __init__(self, x_dim, h_dim, funcs):\n",
    "        self.g = funcs[\"g\"]\n",
    "        self.c = funcs[\"c\"]\n",
    "        \n",
    "        self.x = cp.Variable(x_dim)\n",
    "        self.v = cp.Variable(h_dim)\n",
    "        self.r = cp.Parameter(x_dim, value = np.random.randn(x_dim))\n",
    "        self.w = cp.Parameter(x_dim, value = np.random.randn(x_dim))\n",
    "        self.b = cp.Parameter(1, value = np.random.randn(1))\n",
    "        self.f_der = cp.Parameter(x_dim, value = np.random.randn(x_dim))\n",
    "        self.B_span = cp.Parameter((x_dim, h_dim), value = np.random.randn(x_dim, h_dim))\n",
    "\n",
    "        target = self.x@self.f_der-self.g(self.x, self.w, self.b, TRAIN_SLOPE)-self.c(self.x, self.r, x_dim)\n",
    "        constraints = [self.x >= X_LOWER_BOUND,\n",
    "                       self.x <= X_UPPER_BOUND,\n",
    "                      self.B_span@self.v == self.x-self.r]\n",
    "        objective = cp.Maximize(target)\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        self.layer = CvxpyLayer(problem, parameters=[self.r, self.w, self.b, self.f_der, self.B_span],\n",
    "                                variables=[self.x, self.v])\n",
    "        \n",
    "        \n",
    "    def optimize_X(self, X, w, b, F_DER, B_SPAN):\n",
    "        return self.layer(X, w, b, F_DER, B_SPAN)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gain & Cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(x, w, b):\n",
    "    return x@w + b\n",
    "\n",
    "def f(x, w, b, slope):\n",
    "    return 0.5*cp.norm(cp.hstack([1, (slope*score(x, w, b) + 1)]), 2)\n",
    "\n",
    "def g(x, w, b, slope):\n",
    "    return 0.5*cp.norm(cp.hstack([1, (slope*score(x, w, b) - 1)]), 2)\n",
    "\n",
    "def c(x, r, x_dim):\n",
    "    return cp.sum_squares(x-r)\n",
    "\n",
    "def f_derivative(x, w, b, slope):\n",
    "    return 0.5*cp.multiply(slope*((slope*score(x, w, b) + 1)/cp.sqrt((slope*score(x, w, b) + 1)**2 + 1)), w)\n",
    "\n",
    "funcs = {\"f\": f, \"g\": g, \"f_derivative\": f_derivative, \"c\": c, \"score\": score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "class CAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim, lamb):\n",
    "        torch.manual_seed(0)\n",
    "        np.random.seed(0)\n",
    "        super(CAE, self).__init__()\n",
    "        \n",
    "        self.lamb = lamb\n",
    "        self.x_dim = x_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim, bias = True) # Encoder\n",
    "#         self.fc2 = nn.Linear(h_dim, h_dim, bias = False)\n",
    "        self.fc3 = nn.Linear(h_dim, h_dim, bias = False)\n",
    "        self.fc4 = nn.Linear(h_dim, x_dim, bias = True) # Decoder\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encoder(self, x):\n",
    "        o1 = self.sigmoid(self.fc1(x))\n",
    "#         o2 = self.sigmoid(self.fc2(o1))\n",
    "        return self.sigmoid(self.fc3(o1))\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        return self.fc4(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "            h1 = self.encoder(x)\n",
    "            h2 = self.decoder(h1)\n",
    "            return h1, h2\n",
    "        \n",
    "    def get_spans(self, X):\n",
    "        def func(x):\n",
    "            return self.forward(x)[0]\n",
    "        \n",
    "#         eps = 0.01\n",
    "        B_SPANS = []\n",
    "#         All_S = []\n",
    "        for x in X:\n",
    "            J = jacobian(func, x)\n",
    "            U, S, _ = torch.svd(J.T)\n",
    "#             All_S.append(S)\n",
    "            B_span = U\n",
    "#             B_span = U[:, S>eps]\n",
    "#             if B_span.size()[1] < self.h_dim:\n",
    "#                 pad = torch.zeros((x_dim, self.h_dim-B_span.size()[1]))\n",
    "#                 B_span = torch.cat((B_span, pad), 1)\n",
    "            B_SPANS.append(B_span)\n",
    "#         All_S = torch.stack(All_S)\n",
    "#         print(\"mean of S:\", torch.mean(All_S, 0))\n",
    "#         print(\"std of S:\", torch.std(All_S, 0))\n",
    "        return torch.stack(B_SPANS)\n",
    "    \n",
    "    def contractive_loss(self, x):\n",
    "        def func(x):\n",
    "            return self.encoder(x)\n",
    "        J = jacobian(func, x)\n",
    "        c_loss = torch.norm(J, 2)**2\n",
    "#         print(\"c_loss: \", c_loss)\n",
    "        return c_loss\n",
    "    \n",
    "    def reconstruction_loss(self, x, x_recons):\n",
    "        mse_loss = nn.MSELoss(size_average = False)\n",
    "        r_loss = mse_loss(x_recons, x)\n",
    "#         print(\"r_loss: \", r_loss)\n",
    "        return r_loss\n",
    "        \n",
    "    def loss(self, x, x_recons, h):\n",
    "        \"\"\"Compute the Contractive AutoEncoder Loss\n",
    "        Evalutes the CAE loss, which is composed as the summation of a Mean\n",
    "        Squared Error and the weighted l2-norm of the Jacobian of the hidden\n",
    "        units with respect to the inputs.\n",
    "        See reference below for an in-depth discussion:\n",
    "          #1: http://wiseodd.github.io/techblog/2016/12/05/contractive-autoencoder\n",
    "        Args:\n",
    "            `W` (FloatTensor): (N_hidden x N), where N_hidden and N are the\n",
    "              dimensions of the hidden units and input respectively.\n",
    "            `x` (Variable): the input to the network, with dims (N_batch x N)\n",
    "            recons_x (Variable): the reconstruction of the input, with dims\n",
    "              N_batch x N.\n",
    "            `h` (Variable): the hidden units of the network, with dims\n",
    "              batch_size x N_hidden\n",
    "            `lam` (float): the weight given to the jacobian regulariser term\n",
    "        Returns:\n",
    "            Variable: the (scalar) CAE loss\n",
    "        \"\"\"\n",
    "        r_loss = self.reconstruction_loss(x, x_recons)\n",
    "        c_loss = self.contractive_loss(x)\n",
    "        return r_loss + c_loss.mul_(self.lamb)\n",
    "\n",
    "    def fit(self, X, opt, opt_kwargs={\"lr\":1e-3}, batch_size=128, epochs=100, verbose=False):\n",
    "        train_dset = TensorDataset(X, torch.ones(len(X)))\n",
    "        train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "        opt = opt(self.parameters(), **opt_kwargs)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            train_loss = 0\n",
    "            self.train()\n",
    "            for idx, (Xbatch, _) in enumerate(train_loader):\n",
    "                Xbatch = Variable(Xbatch)\n",
    "                opt.zero_grad()\n",
    "\n",
    "                hidden_representation, recons_x = self.forward(Xbatch)\n",
    "                l = self.loss(Xbatch, recons_x, hidden_representation)\n",
    "                \n",
    "                l.backward()\n",
    "                train_loss += l.item()\n",
    "                opt.step()\n",
    "                \n",
    "#                 with torch.no_grad():\n",
    "#                     r_loss = cae.reconstruction_loss(Xbatch, recons_x).item()\n",
    "#                     c_loss = cae.contractive_loss(Xbatch).item()\n",
    "#                     print(\"reconstruction loss: \", r_loss)\n",
    "#                     print(\"contractive_loss: \", c_loss)\n",
    "\n",
    "#                 if idx % 200 and verbose:\n",
    "#                     print('Train epoch: {} [{}/{}({:.0f}%)]\\t Loss: {:.6f}'.format(\n",
    "#                           epoch, idx*len(Xbatch), len(train_loader.dataset),\n",
    "#                           100*idx/len(train_loader),\n",
    "#                           l.item()))\n",
    "            if verbose:\n",
    "                print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "                     epoch, train_loss / idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 273.4242\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-236-9bd69d3482d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mcae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mcae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_CAE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"lr\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-235-27c43887d8c1>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, opt, opt_kwargs, batch_size, epochs, verbose)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[0mhidden_representation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecons_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecons_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_representation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-235-27c43887d8c1>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, x, x_recons, h)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \"\"\"\n\u001b[0;32m     86\u001b[0m         \u001b[0mr_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreconstruction_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_recons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mc_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontractive_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mc_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlamb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-235-27c43887d8c1>\u001b[0m in \u001b[0;36mcontractive_loss\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mJ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mc_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;31m#         print(\"c_loss: \", c_loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             vj = _autograd_grad((out.reshape(-1)[j],), inputs,\n\u001b[1;32m--> 438\u001b[1;33m                                 retain_graph=True, create_graph=create_graph)\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mel_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mjac_i_el\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvj_el\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp_el\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjac_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36m_autograd_grad\u001b[1;34m(outputs, inputs, grad_outputs, create_graph, retain_graph)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         return torch.autograd.grad(new_outputs, inputs, new_grad_outputs, allow_unused=True,\n\u001b[1;32m--> 147\u001b[1;33m                                    create_graph=create_graph, retain_graph=retain_graph)\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_fill_in_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[0;32m    202\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[0;32m    203\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         inputs, allow_unused)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "diff = 0.001\n",
    "x_dim = len(X_CAE[0])\n",
    "h_dim = x_dim - 7\n",
    "\n",
    "X, Y = load_spam_data()\n",
    "# X, Y = X[:3000], Y[:3000]\n",
    "\n",
    "X, Y, X_CAE, Y_CAE = split_data(X, Y, 0.5)\n",
    "\n",
    "cae = CAE(x_dim, h_dim, 1)\n",
    "cae.fit(X_CAE, opt=torch.optim.Adam, opt_kwargs={\"lr\": (1e-3)}, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        Hval, Xval_recons = cae(Xval_CAE)\n",
    "        r_loss = cae.reconstruction_loss(Xval_CAE, Xval_recons).item()\n",
    "        c_loss = cae.contractive_loss(Xval).item()\n",
    "        print(\"reconstruction loss: \", r_loss)\n",
    "        print(\"contractive_loss: \", c_loss)\n",
    "        print(Xval[0])\n",
    "        print(Xval_recons[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DELTA_GD(nn.Module):\n",
    "    def __init__(self, x_dim, batch_size, slope, model, cae):\n",
    "        torch.manual_seed(0)\n",
    "        np.random.seed(0)\n",
    "        super(DELTA_GD, self).__init__()\n",
    "        \n",
    "        self.slope = slope\n",
    "        self.model = model\n",
    "        self.cae = cae\n",
    "        self.X_opt = torch.nn.parameter.Parameter(torch.zeros((batch_size, x_dim), dtype=torch.float64, requires_grad=True))\n",
    "        \n",
    "    def forward(self):\n",
    "        _, X_opt_recons = self.cae(self.X_opt)\n",
    "        scores = self.model(X_opt_recons)\n",
    "        gains = self.approx_sigmoid(scores)\n",
    "        return gains\n",
    "    \n",
    "    def loss(self, X, gains):\n",
    "        return -(gains - self.quad_cost(X))\n",
    "\n",
    "    def approx_sigmoid(self, scores):\n",
    "        return 0.5*(torch.sqrt((self.slope*scores + 1)**2 + 1) - torch.sqrt((self.slope*scores - 1)**2 + 1))\n",
    "    \n",
    "    def quad_cost(self, X_opt, X):\n",
    "        return torch.sum((X_opt-X)**2, dim=1)\n",
    "    \n",
    "    def fit(self, X, opt, opt_kwargs={\"lr\":1e-3}, epochs=100, verbose=False):\n",
    "        opt = opt([self.X_opt], **opt_kwargs)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            train_loss = 0\n",
    "            self.train()\n",
    "            opt.zero_grad()\n",
    "\n",
    "            gains = self.forward(X)\n",
    "            l = self.loss(gains)\n",
    "\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "                \n",
    "            if verbose:\n",
    "                print('Epoch: {} Loss: {:.4f}'.format(\n",
    "                     epoch, l.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStrategicModel(torch.nn.Module):\n",
    "    def __init__(self, x_dim, funcs, train_slope, eval_slope, strategic=False, manifold=False):\n",
    "        torch.manual_seed(0)\n",
    "        np.random.seed(0)\n",
    "        super(MyStrategicModel, self).__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.h_dim = cae.h_dim\n",
    "        self.train_slope, self.eval_slope = train_slope, eval_slope\n",
    "        self.w = torch.nn.parameter.Parameter(math.sqrt(1/x_dim)*(1-2*torch.rand(x_dim, dtype=torch.float64, requires_grad=True)))\n",
    "        self.b = torch.nn.parameter.Parameter(math.sqrt(1/x_dim)*(1-2*torch.rand(1, dtype=torch.float64, requires_grad=True)))\n",
    "        self.strategic = strategic\n",
    "        self.manifold = manifold\n",
    "        if self.manifold:\n",
    "            self.ccp_train = CCP_MANIFOLD(self.x_dim, self.h_dim, funcs)\n",
    "            self.delta = DELTA_MANIFOLD(self.x_dim, self.h_dim, funcs)\n",
    "        else:\n",
    "            self.ccp_train = CCP(self.x_dim, self.h_dim, funcs)\n",
    "            self.delta = DELTA(self.x_dim, self.h_dim, funcs)\n",
    "        \n",
    "        self.ccp_test = CCP_MANIFOLD(self.x_dim, self.h_dim, funcs)\n",
    "\n",
    "    def forward(self, X, B_SPANS, evaluation=False):\n",
    "        if self.strategic:            \n",
    "            if evaluation:\n",
    "                XT = self.ccp_train.optimize_X(X, self.w, self.b, B_SPANS, self.eval_slope)\n",
    "                X_opt = XT\n",
    "            else:\n",
    "                XT = self.ccp_train.optimize_X(X, self.w, self.b, B_SPANS, self.train_slope)\n",
    "                F_DER = self.get_f_ders(XT, self.train_slope)\n",
    "                X_opt = self.delta.optimize_X(X, self.w, self.b, F_DER, B_SPANS) # Xopt should be equal to XT but we do it again for the gradients\n",
    "                \n",
    "            output = self.score(X_opt)\n",
    "        else:\n",
    "            output = self.score(X)        \n",
    "        return output\n",
    "    \n",
    "    def optimize_X(self, X, B_SPANS):\n",
    "        return self.ccp_test.optimize_X(X, self.w, self.b, B_SPANS, self.eval_slope)\n",
    "    \n",
    "    def normalize_weights(self):\n",
    "        with torch.no_grad():\n",
    "            norm = torch.sqrt(torch.sum(self.w**2) + self.b**2)\n",
    "            self.w /= norm\n",
    "            self.b /= norm\n",
    "    \n",
    "    def score(self, x):\n",
    "        return x@self.w + self.b\n",
    "    \n",
    "    def get_f_ders(self, XT, slope):\n",
    "        return torch.stack([0.5*slope*((slope*self.score(xt) + 1)/torch.sqrt((slope*self.score(xt) + 1)**2 + 1))*self.w for xt in XT])\n",
    "\n",
    "    def calc_accuracy(self, Y, Y_pred):\n",
    "        Y_pred = torch.sign(Y_pred)\n",
    "        num = len(Y)\n",
    "        temp = Y - Y_pred\n",
    "        acc = len(temp[temp == 0])*1./num        \n",
    "        return acc\n",
    "    \n",
    "    def evaluate(self, X, B_SPANS, Y):      \n",
    "        return self.calc_accuracy(Y, self.forward(X, B_SPANS, evaluation=True))\n",
    "    \n",
    "    def loss(self, Y, Y_pred):\n",
    "        return torch.mean(torch.clamp(1 - Y_pred * Y, min=0))\n",
    "    \n",
    "    def save_model(self, train_errors, val_errors, train_losses, val_losses, info, path, comment=None):\n",
    "        if comment is not None:\n",
    "            path += \"/\" + comment\n",
    "            \n",
    "        filename = path + \"/model.pt\"\n",
    "        if not os.path.exists(os.path.dirname(filename)):\n",
    "            os.makedirs(os.path.dirname(filename))\n",
    "        torch.save(self.state_dict(), filename)\n",
    "        \n",
    "        pd.DataFrame(np.array(train_errors)).to_csv(path + '/train_errors.csv')\n",
    "        pd.DataFrame(np.array(val_errors)).to_csv(path + '/val_errors.csv')\n",
    "        pd.DataFrame(np.array(train_losses)).to_csv(path + '/train_losses.csv')\n",
    "        pd.DataFrame(np.array(val_losses)).to_csv(path + '/val_losses.csv')\n",
    "        \n",
    "        with open(path + \"/info.txt\", \"w\") as f:\n",
    "            f.write(info)\n",
    "    \n",
    "    def load_model(self, filename):\n",
    "        self.load_state_dict(torch.load(filename))\n",
    "        self.eval()\n",
    "    \n",
    "    def fit(self, path, X, B_SPANS, Y, Xval, B_SPANSval, Yval, opt, opt_kwargs={\"lr\":1e-3}, batch_size=128, epochs=100, verbose=False, callback=None, comment=None):\n",
    "        train_dset = TensorDataset(X, B_SPANS, Y)\n",
    "        train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "        opt = opt(self.parameters(), **opt_kwargs)\n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_errors = []\n",
    "        val_errors = []\n",
    "        \n",
    "        best_val_error = 1\n",
    "        consecutive_no_improvement = 0\n",
    "\n",
    "        total_time = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            t1 = time.time()\n",
    "            batch = 1\n",
    "            train_losses.append([])\n",
    "            train_errors.append([])\n",
    "            for Xbatch, B_SPANSbatch, Ybatch in train_loader:\n",
    "                opt.zero_grad()\n",
    "                Ybatch_pred = self.forward(Xbatch, B_SPANSbatch)\n",
    "                l = self.loss(Ybatch, Ybatch_pred)\n",
    "                l.backward()\n",
    "                opt.step()\n",
    "                train_losses[-1].append(l.item())\n",
    "                with torch.no_grad():\n",
    "                    e = self.calc_accuracy(Ybatch, Ybatch_pred)\n",
    "                    train_errors[-1].append(1-e)\n",
    "                if verbose:\n",
    "                    print(\"batch %03d / %03d | loss: %3.5f | err: %3.5f\" %\n",
    "                          (batch, len(train_loader), np.mean(train_losses[-1]), np.mean(train_errors[-1])))\n",
    "                batch += 1\n",
    "                if callback is not None:\n",
    "                    callback()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                Yval_pred = self.forward(Xval, B_SPANSval, evaluation=True)\n",
    "                val_loss = self.loss(Yval, Yval_pred).item()\n",
    "                val_losses.append(val_loss)\n",
    "                val_error = 1-self.calc_accuracy(Yval, Yval_pred)\n",
    "                val_errors.append(val_error)\n",
    "                if val_error < best_val_error:\n",
    "                    consecutive_no_improvement = 0\n",
    "                    best_val_error = val_error\n",
    "                    info = \"training time in seconds: {}\\nepoch: {}\\nbatch size: {}\\ntrain slope: {}\\neval slope: {}\\nlearning rate: {}\\nvalidation loss: {}\\nvalidation error: {}\\n\".format(\n",
    "                    time.time()-total_time, epoch, batch_size, self.train_slope, self.eval_slope, opt_kwargs[\"lr\"], val_loss, val_error)\n",
    "                    self.save_model(train_errors, val_errors, train_losses, val_losses, info, path, comment)\n",
    "                    print(\"model saved!\")\n",
    "                else:\n",
    "                    consecutive_no_improvement += 1\n",
    "                    if consecutive_no_improvement >= 4:\n",
    "                        break\n",
    "                \n",
    "            t2 = time.time()\n",
    "            if verbose:\n",
    "                print(\"----- epoch %03d / %03d | time: %03d sec | loss: %3.5f | err: %3.5f\" % (epoch + 1, epochs, t2-t1, val_losses[-1], val_errors[-1]))\n",
    "        print(\"training time: {} seconds\".format(time.time()-total_time)) \n",
    "        return train_errors, val_errors, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5095, 15]) torch.Size([1273, 15]) torch.Size([425, 15]) torch.Size([142, 15])\n",
      "percent of positive samples: 50.35294117647059%\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_spam_data()\n",
    "# X, Y = X[:3000], Y[:3000]\n",
    "\n",
    "X, Y, X_CAE, Y_CAE = split_data(X, Y, 0.9)\n",
    "# X_CAE, Y_CAE = X, Y\n",
    "\n",
    "X_CAE, _, Xval_CAE, _ = split_data(X_CAE, Y_CAE, 0.2)\n",
    "X, Y, Xval, Yval = split_data(X, Y, 0.4)\n",
    "Xval, Yval, Xtest, Ytest = split_data(Xval, Yval, 0.5)\n",
    "\n",
    "\n",
    "print(X_CAE.size(), Xval_CAE.size(), X.size(), Xval.size())\n",
    "print(\"percent of positive samples: {}%\".format(100 * len(Y[Y == 1]) / len(Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298.7372100155535\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n",
      "torch.Size([15, 8])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-f0b31c0de830>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mB_SPANS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_spans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mB_SPANSval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_spans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mB_SPANStest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_spans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-235-27c43887d8c1>\u001b[0m in \u001b[0;36mget_spans\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m#         All_S = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mJ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m#             All_S.append(S)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             vj = _autograd_grad((out.reshape(-1)[j],), inputs,\n\u001b[1;32m--> 438\u001b[1;33m                                 retain_graph=True, create_graph=create_graph)\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mel_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mjac_i_el\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvj_el\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp_el\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjac_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36m_autograd_grad\u001b[1;34m(outputs, inputs, grad_outputs, create_graph, retain_graph)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         return torch.autograd.grad(new_outputs, inputs, new_grad_outputs, allow_unused=True,\n\u001b[1;32m--> 147\u001b[1;33m                                    create_graph=create_graph, retain_graph=retain_graph)\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_fill_in_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[0;32m    202\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[0;32m    203\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         inputs, allow_unused)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "diff = 0.001\n",
    "x_dim = len(X_CAE[0])\n",
    "h_dim = x_dim - 7\n",
    "\n",
    "\n",
    "cae = CAE(x_dim, h_dim, 1)\n",
    "cae.fit(X_CAE, opt=torch.optim.Adam, opt_kwargs={\"lr\": 5*(1e-2)}, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=False)\n",
    "with torch.no_grad():\n",
    "    _, Xval_recons = cae(Xval_CAE)\n",
    "    best_r_loss = cae.reconstruction_loss(Xval_CAE, Xval_recons).item()\n",
    "    print(best_r_loss)\n",
    "        \n",
    "# lamb = 10000000\n",
    "# while True:\n",
    "#     print(\"-----------------------------------------lambda: \", lamb)\n",
    "#     cae = CAE(x_dim, h_dim, lamb)\n",
    "#     cae.fit(X_CAE, opt=torch.optim.Adam, opt_kwargs={\"lr\": 5*(1e-2)}, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=False)\n",
    "#     with torch.no_grad():\n",
    "#         Hval, Xval_recons = cae(Xval_CAE)\n",
    "#         r_loss = cae.reconstruction_loss(Xval_CAE, Xval_recons).item()\n",
    "#         c_loss = cae.contractive_loss(Hval).item()\n",
    "#         print(\"reconstruction loss: \", r_loss)\n",
    "#         print(\"contractive_loss: \", c_loss)\n",
    "#         if r_loss < best_r_loss + diff:\n",
    "#             print(\"found lambda! \", lamb)\n",
    "#             break\n",
    "#         lamb /= 2\n",
    "\n",
    "        \n",
    "B_SPANS = cae.get_spans(X)\n",
    "B_SPANSval = cae.get_spans(Xval)\n",
    "B_SPANStest = cae.get_spans(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lamb = 0.01\n",
    "# cae = CAE(x_dim, h_dim, lamb)\n",
    "# cae.fit(X_CAE, opt=torch.optim.Adam, opt_kwargs={\"lr\": 5*(1e-2)}, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=False)\n",
    "# B_SPANS = cae.get_spans(X)\n",
    "# B_SPANSval = cae.get_spans(Xval)\n",
    "# B_SPANStest = cae.get_spans(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccp_man = CCP_MANIFOLD(x_dim, h_dim, funcs)\n",
    "# ccp_naive = CCP(x_dim, h_dim, funcs)\n",
    "\n",
    "# myX = torch.zeros((1, 15))\n",
    "# mySPAN = B_SPANSval[:1, :, :]\n",
    "# w = torch.randn(x_dim)\n",
    "# b = torch.zeros(1)\n",
    "\n",
    "# X_opt_man = ccp_man.optimize_X(myX, w, b, mySPAN, EVAL_SLOPE)\n",
    "# X_opt_naive = ccp_naive.optimize_X(myX, w, b, mySPAN, EVAL_SLOPE)\n",
    "\n",
    "# print(mySPAN[0])\n",
    "# print(myX[0])\n",
    "# print(X_opt_man[0])\n",
    "# print(X_opt_naive[0])\n",
    "# print(mySPAN[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- training non-strategically----------\n",
      "batch 001 / 018 | loss: 1.00307 | err: 0.54167\n",
      "batch 002 / 018 | loss: 0.85816 | err: 0.43750\n",
      "batch 003 / 018 | loss: 0.86630 | err: 0.43056\n",
      "batch 004 / 018 | loss: 0.81544 | err: 0.40625\n",
      "batch 005 / 018 | loss: 0.71909 | err: 0.37500\n",
      "batch 006 / 018 | loss: 0.69100 | err: 0.34722\n",
      "batch 007 / 018 | loss: 0.66319 | err: 0.33333\n",
      "batch 008 / 018 | loss: 0.67184 | err: 0.32292\n",
      "batch 009 / 018 | loss: 0.63199 | err: 0.30093\n",
      "batch 010 / 018 | loss: 0.59059 | err: 0.27500\n",
      "batch 011 / 018 | loss: 0.58073 | err: 0.26894\n",
      "batch 012 / 018 | loss: 0.55350 | err: 0.25347\n",
      "batch 013 / 018 | loss: 0.55132 | err: 0.25000\n",
      "batch 014 / 018 | loss: 0.55422 | err: 0.24702\n",
      "batch 015 / 018 | loss: 0.55950 | err: 0.24444\n",
      "batch 016 / 018 | loss: 0.54366 | err: 0.23958\n",
      "batch 017 / 018 | loss: 0.54312 | err: 0.24020\n",
      "batch 018 / 018 | loss: 0.54973 | err: 0.23339\n",
      "model saved!\n",
      "----- epoch 001 / 003 | time: 000 sec | loss: 0.38390 | err: 0.14085\n",
      "batch 001 / 018 | loss: 0.45881 | err: 0.16667\n",
      "batch 002 / 018 | loss: 0.41007 | err: 0.16667\n",
      "batch 003 / 018 | loss: 0.36249 | err: 0.13889\n",
      "batch 004 / 018 | loss: 0.40907 | err: 0.14583\n",
      "batch 005 / 018 | loss: 0.43101 | err: 0.15833\n",
      "batch 006 / 018 | loss: 0.47514 | err: 0.17361\n",
      "batch 007 / 018 | loss: 0.46717 | err: 0.17857\n",
      "batch 008 / 018 | loss: 0.48501 | err: 0.18229\n",
      "batch 009 / 018 | loss: 0.45554 | err: 0.17130\n",
      "batch 010 / 018 | loss: 0.43023 | err: 0.15833\n",
      "batch 011 / 018 | loss: 0.40717 | err: 0.15530\n",
      "batch 012 / 018 | loss: 0.42305 | err: 0.15278\n",
      "batch 013 / 018 | loss: 0.44737 | err: 0.16026\n",
      "batch 014 / 018 | loss: 0.43344 | err: 0.15476\n",
      "batch 015 / 018 | loss: 0.43771 | err: 0.15556\n",
      "batch 016 / 018 | loss: 0.43583 | err: 0.15365\n",
      "batch 017 / 018 | loss: 0.44089 | err: 0.15441\n",
      "batch 018 / 018 | loss: 0.44176 | err: 0.15237\n",
      "----- epoch 002 / 003 | time: 000 sec | loss: 0.42411 | err: 0.14085\n",
      "batch 001 / 018 | loss: 0.56354 | err: 0.16667\n",
      "batch 002 / 018 | loss: 0.53609 | err: 0.16667\n",
      "batch 003 / 018 | loss: 0.73933 | err: 0.23611\n",
      "batch 004 / 018 | loss: 0.65688 | err: 0.21875\n",
      "batch 005 / 018 | loss: 0.61697 | err: 0.22500\n",
      "batch 006 / 018 | loss: 0.56810 | err: 0.20833\n",
      "batch 007 / 018 | loss: 0.54113 | err: 0.20238\n",
      "batch 008 / 018 | loss: 0.50809 | err: 0.19271\n",
      "batch 009 / 018 | loss: 0.48343 | err: 0.18519\n",
      "batch 010 / 018 | loss: 0.51518 | err: 0.19583\n",
      "batch 011 / 018 | loss: 0.48916 | err: 0.19318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 012 / 018 | loss: 0.48399 | err: 0.19097\n",
      "batch 013 / 018 | loss: 0.47293 | err: 0.18590\n",
      "batch 014 / 018 | loss: 0.48028 | err: 0.19048\n",
      "batch 015 / 018 | loss: 0.48432 | err: 0.19444\n",
      "batch 016 / 018 | loss: 0.46876 | err: 0.19010\n",
      "batch 017 / 018 | loss: 0.44945 | err: 0.18137\n",
      "batch 018 / 018 | loss: 0.42846 | err: 0.17130\n",
      "model saved!\n",
      "----- epoch 003 / 003 | time: 000 sec | loss: 0.36602 | err: 0.11972\n",
      "training time: 0.1891613006591797 seconds\n",
      "---------- training strategically----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:163: UserWarning: You are solving a parameterized problem that is not DPP. Because the problem is not DPP, subsequent solves will not be faster than the first one. For more information, see the documentation on Discplined Parametrized Programming, at\n",
      "\thttps://www.cvxpy.org/tutorial/advanced/index.html#disciplined-parametrized-programming\n",
      "  warnings.warn(dpp_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 001 / 018 | loss: 0.97612 | err: 0.41667\n",
      "batch 002 / 018 | loss: 0.94684 | err: 0.43750\n",
      "batch 003 / 018 | loss: 1.04153 | err: 0.48611\n",
      "batch 004 / 018 | loss: 0.99997 | err: 0.46875\n",
      "batch 005 / 018 | loss: 0.88129 | err: 0.41667\n",
      "batch 006 / 018 | loss: 0.90203 | err: 0.43056\n",
      "batch 007 / 018 | loss: 0.84413 | err: 0.40476\n",
      "batch 008 / 018 | loss: 0.84150 | err: 0.40625\n",
      "batch 009 / 018 | loss: 0.80138 | err: 0.38889\n",
      "batch 010 / 018 | loss: 0.75003 | err: 0.36250\n",
      "batch 011 / 018 | loss: 0.74494 | err: 0.35606\n",
      "batch 012 / 018 | loss: 0.73544 | err: 0.35069\n",
      "batch 013 / 018 | loss: 0.73023 | err: 0.34936\n",
      "batch 014 / 018 | loss: 0.69761 | err: 0.33333\n",
      "batch 015 / 018 | loss: 0.68636 | err: 0.32500\n",
      "batch 016 / 018 | loss: 0.67432 | err: 0.32031\n",
      "batch 017 / 018 | loss: 0.69185 | err: 0.32843\n",
      "batch 018 / 018 | loss: 0.68185 | err: 0.32326\n",
      "model saved!\n",
      "----- epoch 001 / 003 | time: 068 sec | loss: 0.42936 | err: 0.15493\n",
      "batch 001 / 018 | loss: 0.83827 | err: 0.41667\n",
      "batch 002 / 018 | loss: 0.70887 | err: 0.35417\n",
      "batch 003 / 018 | loss: 0.68928 | err: 0.34722\n",
      "batch 004 / 018 | loss: 0.66563 | err: 0.33333\n",
      "batch 005 / 018 | loss: 0.60529 | err: 0.30000\n",
      "batch 006 / 018 | loss: 0.64287 | err: 0.31944\n",
      "batch 007 / 018 | loss: 0.63469 | err: 0.31548\n",
      "batch 008 / 018 | loss: 0.62656 | err: 0.30729\n",
      "batch 009 / 018 | loss: 0.62158 | err: 0.30556\n",
      "batch 010 / 018 | loss: 0.61789 | err: 0.30000\n",
      "batch 011 / 018 | loss: 0.59880 | err: 0.29167\n",
      "batch 012 / 018 | loss: 0.57166 | err: 0.27431\n",
      "batch 013 / 018 | loss: 0.57414 | err: 0.27564\n",
      "batch 014 / 018 | loss: 0.56380 | err: 0.27083\n",
      "batch 015 / 018 | loss: 0.56795 | err: 0.27222\n",
      "batch 016 / 018 | loss: 0.55607 | err: 0.26562\n",
      "batch 017 / 018 | loss: 0.55790 | err: 0.26716\n",
      "batch 018 / 018 | loss: 0.55387 | err: 0.26539\n",
      "----- epoch 002 / 003 | time: 072 sec | loss: 0.80784 | err: 0.29577\n",
      "batch 001 / 018 | loss: 0.48029 | err: 0.20833\n",
      "batch 002 / 018 | loss: 0.44909 | err: 0.20833\n",
      "batch 003 / 018 | loss: 0.69470 | err: 0.29167\n",
      "batch 004 / 018 | loss: 0.62603 | err: 0.27083\n",
      "batch 005 / 018 | loss: 0.62551 | err: 0.27500\n",
      "batch 006 / 018 | loss: 0.59030 | err: 0.26389\n",
      "batch 007 / 018 | loss: 0.54212 | err: 0.24405\n",
      "batch 008 / 018 | loss: 0.53486 | err: 0.24479\n",
      "batch 009 / 018 | loss: 0.52046 | err: 0.24074\n",
      "batch 010 / 018 | loss: 0.53868 | err: 0.24583\n",
      "batch 011 / 018 | loss: 0.54055 | err: 0.25000\n",
      "batch 012 / 018 | loss: 0.54982 | err: 0.25694\n",
      "batch 013 / 018 | loss: 0.53589 | err: 0.25000\n",
      "batch 014 / 018 | loss: 0.55012 | err: 0.25893\n",
      "batch 015 / 018 | loss: 0.55349 | err: 0.26111\n",
      "batch 016 / 018 | loss: 0.54931 | err: 0.26042\n",
      "batch 017 / 018 | loss: 0.54109 | err: 0.25735\n",
      "batch 018 / 018 | loss: 0.53736 | err: 0.25613\n",
      "----- epoch 003 / 003 | time: 052 sec | loss: 0.45456 | err: 0.16197\n",
      "training time: 193.21405386924744 seconds\n",
      "---------- training strategically----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:163: UserWarning: You are solving a parameterized problem that is not DPP. Because the problem is not DPP, subsequent solves will not be faster than the first one. For more information, see the documentation on Discplined Parametrized Programming, at\n",
      "\thttps://www.cvxpy.org/tutorial/advanced/index.html#disciplined-parametrized-programming\n",
      "  warnings.warn(dpp_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 001 / 018 | loss: 0.98783 | err: 0.33333\n",
      "batch 002 / 018 | loss: 0.94176 | err: 0.39583\n",
      "batch 003 / 018 | loss: 1.03125 | err: 0.45833\n",
      "batch 004 / 018 | loss: 0.98968 | err: 0.44792\n",
      "batch 005 / 018 | loss: 0.87208 | err: 0.40000\n",
      "batch 006 / 018 | loss: 0.88735 | err: 0.41667\n",
      "batch 007 / 018 | loss: 0.82340 | err: 0.38690\n",
      "batch 008 / 018 | loss: 0.82844 | err: 0.39062\n",
      "batch 009 / 018 | loss: 0.78968 | err: 0.37500\n",
      "batch 010 / 018 | loss: 0.74815 | err: 0.35417\n",
      "batch 011 / 018 | loss: 0.74893 | err: 0.35227\n",
      "batch 012 / 018 | loss: 0.73906 | err: 0.34722\n",
      "batch 013 / 018 | loss: 0.73387 | err: 0.34615\n",
      "batch 014 / 018 | loss: 0.70215 | err: 0.33036\n",
      "batch 015 / 018 | loss: 0.69928 | err: 0.32778\n",
      "batch 016 / 018 | loss: 0.68992 | err: 0.32292\n",
      "batch 017 / 018 | loss: 0.70727 | err: 0.33088\n",
      "batch 018 / 018 | loss: 0.68847 | err: 0.32230\n",
      "model saved!\n",
      "----- epoch 001 / 003 | time: 058 sec | loss: 0.41949 | err: 0.15493\n",
      "batch 001 / 018 | loss: 0.75880 | err: 0.37500\n",
      "batch 002 / 018 | loss: 0.66891 | err: 0.33333\n",
      "batch 003 / 018 | loss: 0.58575 | err: 0.29167\n",
      "batch 004 / 018 | loss: 0.58353 | err: 0.29167\n",
      "batch 005 / 018 | loss: 0.54295 | err: 0.26667\n",
      "batch 006 / 018 | loss: 0.57484 | err: 0.28472\n",
      "batch 007 / 018 | loss: 0.55323 | err: 0.27381\n",
      "batch 008 / 018 | loss: 0.55078 | err: 0.27083\n",
      "batch 009 / 018 | loss: 0.53311 | err: 0.26389\n",
      "batch 010 / 018 | loss: 0.51544 | err: 0.25000\n",
      "batch 011 / 018 | loss: 0.49630 | err: 0.24242\n",
      "batch 012 / 018 | loss: 0.49795 | err: 0.23611\n",
      "batch 013 / 018 | loss: 0.49990 | err: 0.23718\n",
      "batch 014 / 018 | loss: 0.48189 | err: 0.22917\n",
      "batch 015 / 018 | loss: 0.48531 | err: 0.23056\n",
      "batch 016 / 018 | loss: 0.47674 | err: 0.22656\n",
      "batch 017 / 018 | loss: 0.47421 | err: 0.22549\n",
      "batch 018 / 018 | loss: 0.46202 | err: 0.21950\n",
      "----- epoch 002 / 003 | time: 062 sec | loss: 0.61888 | err: 0.20423\n",
      "batch 001 / 018 | loss: 0.58834 | err: 0.20833\n",
      "batch 002 / 018 | loss: 0.50600 | err: 0.20833\n",
      "batch 003 / 018 | loss: 0.61246 | err: 0.23611\n",
      "batch 004 / 018 | loss: 0.56282 | err: 0.22917\n",
      "batch 005 / 018 | loss: 0.53927 | err: 0.22500\n",
      "batch 006 / 018 | loss: 0.49223 | err: 0.20833\n",
      "batch 007 / 018 | loss: 0.44787 | err: 0.19048\n",
      "batch 008 / 018 | loss: 0.42301 | err: 0.18229\n",
      "batch 009 / 018 | loss: 0.39514 | err: 0.17130\n",
      "batch 010 / 018 | loss: 0.42677 | err: 0.18333\n",
      "batch 011 / 018 | loss: 0.41812 | err: 0.18182\n",
      "batch 012 / 018 | loss: 0.41961 | err: 0.18403\n",
      "batch 013 / 018 | loss: 0.40099 | err: 0.17628\n",
      "batch 014 / 018 | loss: 0.42004 | err: 0.18452\n",
      "batch 015 / 018 | loss: 0.41544 | err: 0.18333\n",
      "batch 016 / 018 | loss: 0.39541 | err: 0.17448\n",
      "batch 017 / 018 | loss: 0.39244 | err: 0.17402\n",
      "batch 018 / 018 | loss: 0.39113 | err: 0.17416\n",
      "----- epoch 003 / 003 | time: 058 sec | loss: 0.53185 | err: 0.18310\n",
      "training time: 179.19477534294128 seconds\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "PATH = \"C:/Users/sagil/Desktop/nir_project/models/manifold/\" + now.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 24\n",
    "\n",
    "# non-strategic classification\n",
    "print(\"---------- training non-strategically----------\")\n",
    "non_strategic_model = MyStrategicModel(x_dim, funcs, TRAIN_SLOPE, EVAL_SLOPE, strategic=False)\n",
    "\n",
    "non_strategic_model.fit(PATH, X, B_SPANS, Y, Xval, B_SPANSval, Yval,\n",
    "                                opt=torch.optim.Adam, opt_kwargs={\"lr\": 5*(1e-1)},\n",
    "                                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=True,\n",
    "                                comment=\"non_strategic\")\n",
    "\n",
    "# strategic classification\n",
    "print(\"---------- training strategically----------\")\n",
    "strategic_model_naive = MyStrategicModel(x_dim, funcs, TRAIN_SLOPE, EVAL_SLOPE, strategic=True, manifold=False)\n",
    "\n",
    "strategic_model_naive.fit(PATH, X, B_SPANS, Y, Xval, B_SPANSval, Yval,\n",
    "                                opt=torch.optim.Adam, opt_kwargs={\"lr\": 5*(1e-1)},\n",
    "                                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=True,\n",
    "                                comment=\"strategic_naive\")\n",
    "\n",
    "# strategic classification\n",
    "print(\"---------- training strategically----------\")\n",
    "strategic_model_man = MyStrategicModel(x_dim, funcs, TRAIN_SLOPE, EVAL_SLOPE, strategic=True, manifold=True)\n",
    "\n",
    "strategic_model_man.fit(PATH, X, B_SPANS, Y, Xval, B_SPANSval, Yval,\n",
    "                                opt=torch.optim.Adam, opt_kwargs={\"lr\": 5*(1e-1)},\n",
    "                                batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=True,\n",
    "                                comment=\"strategic_man\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\expressions\\expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py:163: UserWarning: You are solving a parameterized problem that is not DPP. Because the problem is not DPP, subsequent solves will not be faster than the first one. For more information, see the documentation on Discplined Parametrized Programming, at\n",
      "\thttps://www.cvxpy.org/tutorial/advanced/index.html#disciplined-parametrized-programming\n",
      "  warnings.warn(dpp_error_msg)\n"
     ]
    }
   ],
   "source": [
    "\"C:/Users/sagil/Desktop/nir_project/models/manifold/30-01-2021_11-20-43\"\n",
    "\n",
    "non_strategic_model = MyStrategicModel(x_dim, funcs, TRAIN_SLOPE, EVAL_SLOPE, strategic=False)\n",
    "non_strategic_model.load_model(PATH + \"/non_strategic/model.pt\")\n",
    "# non_strategic_model.normalize_weights()\n",
    "\n",
    "strategic_model_naive = MyStrategicModel(x_dim, funcs, TRAIN_SLOPE, EVAL_SLOPE, strategic=True, manifold=False)\n",
    "strategic_model_naive.load_model(PATH + \"/strategic_naive/model.pt\")\n",
    "# strategic_model_naive.normalize_weights()\n",
    "\n",
    "strategic_model_man = MyStrategicModel(x_dim, funcs, TRAIN_SLOPE, EVAL_SLOPE, strategic=True, manifold=True)\n",
    "strategic_model_man.load_model(PATH + \"/strategic_man/model.pt\")\n",
    "# strategic_model_man.normalize_weights()\n",
    "\n",
    "# calculate results\n",
    "accuracies = np.zeros(4)\n",
    "\n",
    "# non strategic model & non strategic data\n",
    "accuracies[0] = (non_strategic_model.evaluate(Xtest, B_SPANStest, Ytest))\n",
    "\n",
    "# naive strategic model & strategic data\n",
    "Xtest_opt = strategic_model_naive.optimize_X(Xtest, B_SPANStest)\n",
    "test_scores = strategic_model_naive.score(Xtest_opt)\n",
    "accuracies[1] = (strategic_model_naive.calc_accuracy(Ytest, test_scores))\n",
    "\n",
    "# manifold strategic model & strategic data\n",
    "Xtest_opt = strategic_model_man.optimize_X(Xtest, B_SPANStest)\n",
    "test_scores = strategic_model_man.score(Xtest_opt)\n",
    "accuracies[2] = (strategic_model_man.calc_accuracy(Ytest, test_scores))\n",
    "\n",
    "# non strategic model & strategic data\n",
    "Xtest_opt = non_strategic_model.optimize_X(Xtest, B_SPANStest)\n",
    "accuracies[3] = (non_strategic_model.evaluate(Xtest_opt, B_SPANStest, Ytest))\n",
    "\n",
    "pd.DataFrame(accuracies).to_csv(PATH + '/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0683], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2900], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2414], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagil\\Anaconda3\\envs\\funcPred\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox  6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (mpl.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: mpl.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * mpl.ratio);\n",
       "                canvas.setAttribute('height', height * mpl.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / mpl.ratio,\n",
       "        fig.canvas.height / mpl.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / mpl.ratio;\n",
       "    fig.root.removeEventListener('remove', this._remove_fig_handler);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / mpl.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function () {\n",
       "    this.close_ws(this, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "    el.addEventListener('remove', this._remove_fig_handler);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAgAElEQVR4Xu3dCaxV1dn/8ediaitWoBq1ghc0FZQhsYKVGbWhDrERcKC2DQrO2ipo4oBavbQCFpqC0TJXJqslNM61aoxCLah1KKZh1FpUuDgL1baCyn2z9tt7vdPh7nWetc/ae63vScy/75+99vBZz9nrx7PPOVTV1dXVCS8EEEAAAQQQQACBaASqCIDRzDUXigACCCCAAAIIJAIEQAoBAQQQQAABBBCITIAAGNmEc7kIIIAAAggggAABkBpAAAEEEEAAAQQiEyAARjbhXC4CCCCAAAIIIEAApAYQQAABBBBAAIHIBAiAkU04l4sAAggggAACCBAAqQEEEEAAAQQQQCAyAQJgZBPO5SKAAAIIIIAAAgRAagABBBBAAAEEEIhMgAAY2YRzuQgggAACCCCAAAGQGkAAAQQQQAABBCITIABGNuFcLgIIIIAAAgggQACkBhBAAAEEEEAAgcgECICRTTiXiwACCCCAAAIIEACpAQQQQAABBBBAIDIBAmBkE87lIoAAAggggAACBEBqAAEEEEAAAQQQiEyAABjZhHO5CCCAAAIIIIAAAZAaQAABBBBAAAEEIhMgAEY24VwuAggggAACCCBAAKQGEEAAAQQQQACByAQIgJFNOJeLAAIIIIAAAggQAKkBBBBAAAEEEEAgMgECYGQTzuUigAACCCCAAAIEQGoAAQQQQAABBBCITIAAGNmEc7kIIIAAAggggAABkBpAAAEEEEAAAQQiEyAARjbhXC4CCCCAAAIIIEAApAYQQAABBBBAAIHIBAiAkU04l4sAAggggAACCBAAqQEEEEAAAQQQQCAyAQJgZBPO5SKAAAIIIIAAAgRAagABBBBAAAEEEIhMgAAY2YRzuQgggAACCCCAAAGQGkAAAQQQQAABBCITIABGNuFcLgIIIIAAAgggQACkBhBAAAEEEEAAgcgECICRTTiXiwACCCCAAAIIEACpAQQQQAABBBBAIDIBAmBkE87lIoAAAggggAACBEBqAAEEEEAAAQQQiEyAABjZhHO5CCCAAAIIIIAAAZAaQAABBBBAAAEEIhMgAEY24VwuAggggAACCCBAAKQGEEAAAQQQQACByAQIgJFNOJeLAAIIIIAAAggQAKkBBBBAAAEEEEAgMgECYGQTzuUigAACCCCAAAIEQGoAAQQQQAABBBCITIAAGNmEc7kIIIAAAggggAABkBpAAAEEEEAAAQQiEyAARjbhXC4CCCCAAAIIIEAApAYQQAABBBBAAIHIBAiAkU04l4sAAggggAACCBAAqQEEEEAAAQQQQCAyAQKgYsJ3794ttbW1st9++0lVVZViTwxFAAEEEEAAgUoJ1NXVyccffyydO3eWdu3aVeqwuToOAVAxHVu2bJHq6mrFHhiKAAIIIIAAAr4E3nrrLTn00EN9Hd7rcQmACv4dO3ZIp06dxBRQhw4dFHtiKAIIIIAAAghUSuBf//pX0sDZvn27dOzYsVKHzdVxCICK6TAFZArHBEECoAKSoQgggAACCFRQgPVbhACoKDgKSIHHUAQQQAABBDwJsH4TAFWlRwGp+BiMAAIIIICAFwHWbwKgqvAoIBUfgxFAAAEEEPAiwPpNAFQVHgWk4mMwAggggAACXgRYvwmAqsKjgFR8DEYAAQQQQMCLAOs3AVBVeBSQio/BCCCAAAIIeBFg/SYAqgqPAlLxMRgBBBBAAAEvAqzfBEBV4VFAKj4GI4AAAggg4EWA9ZsAqCo8CkjFx2AEEEAAAQS8CLB+EwBVhUcBqfgYjAACCCCAgBcB1m8CoKrwKCAVH4MRQAABBBDwIsD6TQBUFR4FpOJjMAIIIIAAAl4EWL8JgKrCo4BUfAxGAAEEEEDAiwDrNwFQVXgxFlDVpKpWzepuqVNZMhgBBBBAAIFKCcS4fje3raqrq2PlLrPiYiwgAmCZxcIwBBBAAIHcCMS4fhMAHZZfjAVEAHRYQOwKAQQQQMCLQIzrNwHQYanFWEAEQIcFxK4QQAABBLwIxLh+Bx0AZ82aJdOnT5dt27ZJ7969ZebMmTJ06NCSxbVz5075+c9/Lnfffbe8/fbbcuihh8qNN94o559/fqqCjLGACICpSoONEEAAAQRyLBDj+h1sAFy2bJmMGTNGTAgcPHiwzJ07VxYsWCDr1q2Trl27tlqGI0aMkHfeeUduvfVWOeKII+Tdd9+Vzz//XAYNGpSqbGMsIAJgqtJgIwQQQACBHAvEuH4HGwD79+8vffv2ldmzZzdcY8+ePWXkyJEyderUFmX42GOPyTnnnCOvv/667L///mWVaYwFRAAsq1QYhAACCCCQI4EY1+8gA+CuXbukffv2snz5chk1alTDNY4fP17WrFkjK1eubFF2l19+uWzatEmOPfZYWbp0qey7775y+umnyy9+8QvZZ599Wi1T88jY/Ff/MgVUXV0tO3bskA4dOuSotLM7FQJgdrbsGQEEEECgMgIEwEB+B7C2tla6dOkiq1atavL4dsqUKbJ48WLZuHFji4o65ZRTZMWKFTJ8+HC5+eab5f333xcTCr/73e/KXXfd1WoF1tTUyKRJk1r8GQFQpK6mxJuWXxmqzN2MoyCAAAIIpBYgAAYWAFevXi0DBw5sKIDJkycn3b0NGza0KIqTTjpJnnnmmeTLHx07dkz+/L777pOzzjpL/v3vf7faBaQDKFKyA0gATH3jYUMEEEAAAb8CBMBAAmA5j4DPO++8pGP42muvNVTh+vXrpVevXsmj4e7du7dZnTEWEAGwzbJgAwQQQACBnAvEuH43n5Jg/iUQ8yWQfv36Jd8Crn+ZMGe+6dval0DmzZsnEyZMSL75+/Wvfz0Z8uCDD8oZZ5whn3zyScnPATYGjLGACIA5v6txeggggAACbQrEuH4HGwDrfwZmzpw5yWNgE/Dmz58va9eulW7dusnEiRNl69atsmTJksTAhDzzLeEBAwYkn+sznwG88MIL5fjjj0/GpXnFWEAEwDSVwTYIIIAAAnkWiHH9DjYAmgsz3b9p06YlPwTdp08fmTFjhgwbNiy55rFjx8rmzZuTL37Uv8xnA6+44orkUfABBxwgo0ePTn4TsNS3gJvjxVhABMA839I4NwQQQACBNAIxrt9BB8A0k+5ymxgLiADosoLYFwIIIICAD4EY128CoMNKi7GACIAOC4hdIYAAAgh4EYhx/SYAOiy1GAuIAOiwgNgVAggggIAXgRjXbwKgw1KLsYAIgA4LiF0hgAACCHgRiHH9JgA6LLUYC4gA6LCA2BUCCCCAgBeBGNdvAqDDUouxgAiADguIXSGAAAIIeBGIcf0mADostRgLiADosIDYFQIIIICAF4EY128CoMNSi7GACIAOC4hdIYAAAgh4EYhx/SYAOiy1GAuIAOiwgNgVAggggIAXgRjXbwKgw1KLsYAIgA4LiF0hgAACCHgRiHH9JgA6LLUYC4gA6LCA2BUCCCCAgBeBGNdvAqDDUouxgAiADguIXSGAAAIIeBGIcf0mADostRgLiADosIDYFQIIIICAF4EY128CoMNSi7GACIAOC4hdIYAAAgh4EYhx/SYAOiy1GAuIAOiwgNgVAggggIAXgRjXbwKgw1KLsYAIgA4LiF0hgAACCHgRiHH9JgA6LLUYC4gA6LCA2BUCCCCAgBeBGNdvAqDDUouxgAiADguIXSGAAAIIeBGIcf0mADostRgLiADosIDYFQIIIICAF4EY128CoMNSi7GACIAOC4hdIYAAAgh4EYhx/SYAOiy1GAuIAOiwgNgVAggggIAXgRjXbwKgw1KLsYAIgA4LiF0hgAACCHgRiHH9JgA6LLUYC4gA6LCA2BUCCCCAgBeBGNdvAqDDUouxgAiADguIXSGAAAIIeBGIcf0mADostRgLiADosIDYFQIIIICAF4EY128CoMNSi7GACIAOC4hdIYAAAgh4EYhx/SYAOiy1GAuIAOiwgNgVAggggIAXgRjXbwKgw1KLsYAIgA4LiF0hgAACCHgRiHH9JgA6LLUYC4gA6LCA2BUCCCCAgBeBGNdvAqDDUouxgAiADguIXSGAAAIIeBGIcf0mADostRgLiADosIDYFQIIIICAF4EY128CoMNSi7GACIAOC4hdIYAAAgh4EYhx/SYAOiy1GAuIAOiwgNgVAggggIAXgRjXbwKgw1KLsYAIgA4LiF0hgAACCHgRiHH9JgA6LLUYC4gA6LCA2BUCCCCAgBeBGNdvAqDDUouxgAiADguIXSGAAAIIeBGIcf0mADostRgLiADosIDYFQIIIICAF4EY128CoMNSi7GACIAOC4hdIYAAAgh4EYhx/SYAOiy1GAuIAOiwgNgVAggggIAXgRjXbwKgw1KLsYAIgA4LiF0hgAACCHgRiHH9JgA6LLUYC4gA6LCA2BUCCCCAgBeBGNdvAqDDUouxgAiADguIXSGAAAIIeBGIcf0mADostRgLiADosIDYFQIIIICAF4EY128CoMNSi7GACIAOC4hdIYAAAgh4EYhx/SYAOiy1UAuoqmoPSDWt/2FdTYkxdXUOxdkVAggggAACeoFQ128bmaq6OlZoG7DG24ZaQATAciuCcQgggAACRRAIdf22sScA2mg12zbUAiIAKoqCoQgggAACuRcIdf22gScA2mgRAEV4BKyoGIYigAACCORBgAAoQgBUVGKoBUQHUFEUDEUAAQQQyL1AqOu3DXxQAXDWrFkyffp02bZtm/Tu3VtmzpwpQ4cObdNj1apVcvzxx0ufPn1kzZo1bW5fv0GoBUQATF0CbIgAAgggUECBUNdvm6kIJgAuW7ZMxowZIyYEDh48WObOnSsLFiyQdevWSdeuXUua7NixQ/r27StHHHGEvPPOOwRAESEA2ryF2BYBBBBAoGgCBMCAHgH3798/CXKzZ89uqMOePXvKyJEjZerUqSVr85xzzpHu3bvLXnvtJQ888AABkABYtPsY54sAAgggYClAAAwkAO7atUvat28vy5cvl1GjRjWUwfjx45NAt3LlylZLY+HChUnH8Nlnn5Vbb721zQC4c+dOMf81fgRcXV0tpovYoUMHy/LL7+Z0APM7N5wZAggggIBegAAYSACsra2VLl26iPks36BBgxoqY8qUKbJ48WLZuHFji2p59dVXZciQIfLMM89Ijx49pKamps0AaLaZNGlSi30RAEX4IWj9DYk9IIAAAghURoAAGFgAXL16tQwcOLCheiZPnixLly6VDRs2NKmoL774QgYMGCAXXHCBXHrppcmfpQmAdAANFP8SSGVuTxwFAQQQQCArAQJgIAHQ9hHw9u3b5Rvf+Ebyub/61+7du8X8oyjm/++JJ56Q7373u23WXagFxCPgNqeeDRBAAAEECiwQ6vptMyXBfAvYfAmkX79+yWf66l+9evWSESNGtPgSiAl75tvBjV9m3FNPPSV/+MMf5PDDD5d99923TcdQC4gA2ObUswECCCCAQIEFQl2/baYkmABY/zMwc+bMSR4Dz5s3T+bPny9r166Vbt26ycSJE2Xr1q2yZMmSVn3SPAJuPjDUAiIA2ryF2BYBBBBAoGgCoa7fNvMQTAA0F226eNOmTUt+CNr8qPOMGTNk2LBhicfYsWNl8+bNsmLFCgJgGxVCALR5C7EtAggggEDRBAiAgXwG0FfhhVpABEBfFcVxEUAAAQQqIRDq+m1jF1QH0ObCXWwbagERAF1UB/tAAAEEEMirQKjrt403AdBGq9m2oRYQAVBRFAxFAAEEEMi9QKjrtw08AdBGiwDI7wAq6oWhCCCAAAL5ECAA8hlAVSWGWkB0AFVlwWAEEEAAgZwLhLp+27DTAbTRogNIB1BRLwxFAAEEEMiHAAGQDqCqEkMtIDqAqrJgMAIIIIBAzgVCXb9t2OkA2mjRAaQDqKgXhiKAAAII5EOAAEgHUFWJoRYQHUBVWTAYAQQQQCDnAqGu3zbsdABttOgA0gFU1AtDEUAAAQTyIUAApAOoqsRQC4gOoKosGIwAAgggkHOBUNdvG3Y6gDZadADpACrqhaEIIIAAAvkQIADSAVRVYqgFRAdQVRYMRgABBBDIuUCo67cNOx1AGy06gHQAFfXCUAQQQACBfAgQAOkAqiox1AKiA6gqCwYjgAACCORcINT124adDqCNFh1AOoCKemEoAggggEA+BAiAdABVlRhqAdEBVJUFgxFAAAEEci4Q6vptw04H0EaLDiAdQEW9MBQBBBBAIB8CBEA6gKpKDLWA6ACqyoLBCCCAAAI5Fwh1/bZhpwNoo0UHkA6gol4YigACCCCQDwECIB1AVSWGWkB0AFVlwWAEEEAAgZwLhLp+27DTAbTRogNIB1BRLwxFAAEEEMiHAAGQDqCqEkMtIDqAqrJgMAIIIIBAzgVCXb9t2OkA2mjRAaQDqKgXhiKAAAII5EOAAEgHUFWJoRYQHUBVWTAYAQQQQCDnAqGu3zbsdABttOgA0gFU1AtDEUAAAQTyIUAApAOoqsRQC4gOoKosGIwAAgggkHOBUNdvG3Y6gDZadADpACrqhaEIIIAAAvkQIADSAVRVYqgFRAdQVRYMRgABBBDIuUCo67cNOx1AGy06gHQAFfXCUAQQQACBfAgQAOkAqiox1AKiA6gqCwYjgAACCORcINT124adDqCNFh1AOoCKemEoAggggEA+BAiAdABVlRhqAdEBVJUFgxFAAAEEci4Q6vptw04H0EaLDiAdQEW9MBQBBBBAIB8CBEA6gKpKDLWA6ACqyoLBCCCAAAI5Fwh1/bZhpwNoo0UHkA6gol4YigACCCCQDwECIB1AVSWGWkB0AFVlwWAEEEAAgZwLhLp+27DTAbTRogNIB1BRLwxFAAEEEMiHAAGQDqCqEkMtIDqAqrJgMAIIIIBAzgVCXb9t2OkA2mjRAaQDqKgXhiKAAAII5EOAAEgHUFWJoRYQHUBVWTAYAQQQQCDnAqGu3zbsdABttOgA0gFU1AtDEUAAAQTyIUAApAOoqsRQC4gOoKosGIwAAgggkHOBUNdvG3Y6gDZadADpACrqhaEIIIAAAvkQIADSAVRVYqgFRAdQVRYMRgABBBDIuUCo67cNOx1AGy06gHQAFfXCUAQQQACBfAgQAOkAqiox1AKiA6gqCwYjgAACCORcINT124adDqCNFh1AOoCKemEoAggggEA+BAiAdABVlRhqAdEBVJUFgxFAAAEEci4Q6vptwx5UB3DWrFkyffp02bZtm/Tu3VtmzpwpQ4cObdXjvvvuk9mzZ8uaNWtk586dyfY1NTVy8sknp/YLtYAIgKlLgA0RQAABBAooEOr6bTMVwQTAZcuWyZgxY8SEwMGDB8vcuXNlwYIFsm7dOunatWsLkwkTJkjnzp3lxBNPlE6dOsnChQvlV7/6lTz//PNyzDHHpDIMtYAIgKmmn40QQAABBAoqEOr6bTMdwQTA/v37S9++fZOuXv2rZ8+eMnLkSJk6dWoqE9MF/MEPfiA333xzqu1DLSACYKrpZyMEEEAAgYIKhLp+20xHEAFw165d0r59e1m+fLmMGjWq4frHjx+fPOJduXJlmya7d++Www47TK699lr56U9/2ur25lGx+a/+ZQqourpaduzYIR06dGjzGEXZgABYlJniPBFAAAEEyhEgAAbyJZDa2lrp0qWLrFq1SgYNGtRQC1OmTJHFixfLxo0b26wP89nB2267TdavXy8HHXRQq9ubzwhOmjSpxZ8RAEXqakoQ19W1ac8GCCCAAAIIVFKAABhYAFy9erUMHDiwoYYmT54sS5culQ0bNuyxru6991658MIL5cEHH5Thw4eX3JYOoPAzMJW8Q3EsBBBAAIFMBAiAgQRAzSNg8+WRcePGJY+PTzvtNKtCC7WAeARsVQZsjAACCCBQMIFQ12+baQjiM4Dmgs2XQPr165d8C7j+1atXLxkxYkTJL4GYzt/5558v5v81XxaxfYVaQARA20pgewQQQACBIgmEun7bzEEwAbD+Z2DmzJmTPAaeN2+ezJ8/X9auXSvdunWTiRMnytatW2XJkiWJjwl95557rtx+++1yxhlnNJjts88+0rFjx1SGoRYQATDV9LMRAggggEBBBUJdv22mI5gAaC7adP+mTZuW/BB0nz59ZMaMGTJs2LDEY+zYsbJ582ZZsWJF8n+fcMIJrX47+LzzzpNFixalMgy1gAiAqaafjRBAAAEECioQ6vptMx1BBUCbC3exbagFRAB0UR3sA4FiCVRNqmr1hOtu4Zv8xZpJzjaNQKjrd5prr9+GAGij1WzbUAuIAKgoCoYiUFABAmBBJ47TLksg1PXbBoMAaKNFAORnYBT1wlAE8ixAAMzz7HBurgUIgIH8DIzrwki7v1ALiA5g2gpgOwTCESAAhjOXXEnbAqGu321f+Zdb0AG00aIDSAdQUS8MRSDPAgTAPM8O5+ZagABIB1BVU6EWEB1AVVkwGIFCChAACzltnHSZAqGu3zYcdABttOgA0gFU1AtDEcizAAEwz7PDubkWIADSAVTVVKgFRAdQVRYMRqCQAgTAQk4bJ12mQKjrtw0HHUAbLTqAdAAV9cJQBPIsQADM8+xwbq4FCIB0AFU1FWoB0QFUlQWDESikAAGwkNPGSZcpEOr6bcNBB9BGiw4gHUBFvTAUgTwLEADzPDucm2sBAiAdQFVNhVpAdABVZcFgBAopQAAs5LRx0mUKhLp+23DQAbTRogNIB1BRLwxFIM8CBMA8zw7n5lqAAEgHUFVToRYQHUBVWTAYgUIKhBwAS93T6uoKOVVhnnSFJynU9dumOOgA2mjRAaQDqKgXhiKQZwECYJ5nJ4JzIwBWfJIJgAryUP8GQQdQURQMRaCgAgTAgk5cKKdNAKz4TBIAFeQEwC/x6mpKQPKMRVFhDEWgcgIEwMpZc6RWBAiAFS8LAqCCnABIAFSUD0MRSC9QgcWRAJh+Ooq+ZS7nugI13njeQl2/bWqTAGij1WzbUAuIR8CKomAoAlkIVGBxzGUocGRZAT5HZ1qZ3eRyris8SaGu3zYVRAC00SIA8iUQRb0wFIGyBSqwOOYyFJQN1nRgBfgcnWlldpPLua7wJBEA+RkY1bst1AKiA6gqCwYj4F6gAotjLkOBI8kK8Dk60//tJuMTzuVcZ3zNzSco1PXbphDpANpo0QGkA6ioF4YiULZABRbHXIaCssEK3gHMeL5zOdcZXzMBsOWbiQCouMGE+jcIOoCKomAoAlkIVGBxzGUocGRZAT5HZ0oHsAVkRr8kEer6bVOIBEAbLTqAdAAV9cJQBMoWqECCIQCWPTvuB2Y837mc64yvmQ4gHUCnb9RQ/wZBB9BpmbAzBPQCFVgccxkK9HLJHirA5+hM6QDSAXRbSnvaGx1AhTUB8Es8fghaUUgMRaAtgQokGAJgW5NQwT/PeL5zOdcZXzMdQDqATt/BBEACoNOCYmcIlBKowOKYy1DgqCIqwOfoTOkA0gF0W0p0ADPyJAASADMqLXaLQFOBCiQYAmCOii7j+c7lXGd8zXQA6QA6fYcTAAmATguKnSFABzCTGqhwttBfg6MTLvl57pqqVs+x7pY6/bmXuwdH15z28KGu32mv32zHZwBttJptG2oB8SUQRVEwFIEsBCqwOOayK+TIsgJ8js70f7txdMIEwNLTEur6bVOIBEAbLQIgPwOjqBeGItCWQMkQVlNipMPfSPN57LZctH/uKE9pTyP9eEcnTAAkAO6p6AiA6d+SLbYM9W8QdAAVRcFQBBQCPkOYz2MryFINdZSnUh3LyUaOTpgASAAkADp5R7bcCQHwSxN+BiajImO3UQn4DGE+j531JDvKU1mf5pf7d3TCBEACIAEwo7ctAZAAmFFpsdtIBXyGMJ/Hznq6HeWprE+TANiasMOPOTTefajrt02R8gjYRqvZtqEWEI+AFUXBUAQUAj5DmM9jK8hSDSUANmPiW8AS6vqd6g3xv40IgDZaBEC+BKKoF4Yi0JaAzxDm89htuWj/nABIAGxeQwRAfgZGdV8JtYDoAKrKgsEIlC3gM4T5PHbZYCkHEgAJgATAlm8WOoApbyCtbUYA/FKFL4EoComhCNQ/kplU4gd6+RkYVY3kMQCWCtzmQl3dT/kSSOmyCXX9tnmjEABttHgEzCNgRb0wFIG2BHx24Xweuy0X7Z8TAOkA0gGkA6i9jzQZH+rfIHgE7LRM2BkCqQV8hjCfx04NVOaGBEACIAGQAFjm7aP1YQTAL11cPbJwOkHsDIGCCfgMYT6PnfU0EQAJgARAAqDT+wwBkADotKDYWS4EKvFv4lp/NovPAKpqgwBIACQAEgBVN5FYCohHwE7LhJ0VTIAA2HTCQujuEwAJgLGs3za3W74EYqPVbFs6gHQAFeXD0JwKEAAJgJUoTb4F3Ey5wik91PXbpnYJgDZaBEC+BayoF4YWQ4AASACsRKUSAAmAlaizPR2DAKiYgVD/BsEjYEVRMLTwApX4MgSfAaxsmdh6m7Oru6Uu05MkABIAMy2wFDsnAKZAKrUJAZBHwIryYWhOBQiA8XQApcS/iUsA9PDm5BFwxdEJgApyAiABUFE+DM2pAAGQAEgA9PDmJABWHJ0AqCAnABIAFeXD0JwKEAAJgARAD29OAmDF0YMKgLNmzZLp06fLtm3bpHfv3jJz5kwZOnRoSdSVK1fK1VdfLWvXrpXOnTvLtddeK5deemnqSSAAEgBTFwsbFkaAAEgAJAB6eLsSACuOHkwAXLZsmYwZM0ZMCBw8eLDMnTtXFixYIOvWrZOuXbu2gP3nP/8pffr0kYsuukguueQSWbVqlVx++eVy7733yplnnplqIgiABMBUhcJGhRIgABIACYAe3rIEwIqjBxMA+/fvL3379pXZs2c3IPbs2VNGjhwpU6dObQF73XXXyUMPPSTr169v+DPT/XvllVfk2WefTTURBEACYKpCYaNCCRAACYAEQA9vWQJgxdGDCIC7du2S9u3by/Lly2XUqFENiOPHj2ucOoMAACAASURBVJc1a9aIedTb/DVs2DA55phj5Pbbb2/4o/vvv19Gjx4t//nPf+QrX/lKizE7d+4U81/9ywTA6upq2bFjh3To0KHik5fVAfkZmKxk2W8RBAiABMBoA2Cpf3IwAcn2Z3GEAFjx22MQAbC2tla6dOmSPMYdNGhQA+KUKVNk8eLFsnHjxhawPXr0kLFjx8oNN9zQ8GerV69OHh+b/R1yyCEtxtTU1MikSZNa/P9nFQBtf7sq5H+yaY8/1+Do30m19U7uiZ6OXfK4Zdyoba/b1TWbU83jsbNe5yp+l292wAqvsw1HL9xfLB1BOdqN77KxPr71ezvj311sfgGhPsGzmaigAqAJcAMHDmy4/smTJ8vSpUtlw4YNrQbAcePGycSJExv+zATIIUOGJF8i+eY3v+m9A2j9BnIURmwKyPW2ttfsM4T5PDYBsFnllZHaWJibdfo8NXiSsyjxe3xZ/xjzHu9fjgrE0W5c32oz35/tvbzSc00AFAkiAFbqEXCl/wZh/QYiAKpWNFtvAmB2IaxkIHBY4yzMqreLdYAoqwNY4a5Qk4tyVCCOdmPtndcBlfinFtNcOwEwkABoJtt8CaRfv37Jt4DrX7169ZIRI0aU/BLIww8/nHxLuP512WWXJZ8ZzMuXQGwDictHc2neQFlsY3vNPkOYz2PTAcwufJbRTMzirZDZPn0FEgJgZQN3ZgWk3DEBUAnocHgQHUDjUf8zMHPmzEkeA8+bN0/mz5+f/MZft27dkke9W7dulSVLliR89T8DY34CxvwUjAl95lvAefoZGNswRADUhQJbbwKgztuMtjUPocYd3r/L2hUBMCWbIyhHu0l50myWVoAOYEAdQDPppvs3bdq05DN85jf+ZsyYIebbvuZlvvCxefNmWbFiRUN9mG8HX3XVVQ0/BG1+GiZPPwQd4+Joe80+Q5jPY9MB1IfPtAtFaNv5CiR0AOkA5um9RAAMLABWuriyLiDbMBRCd8T2mn2GMJ/HJgASAMu93xEAU8o5gnK0m5QnzWZpBbJev9Oeh8/tgnkE7AMx6wKyDUMEQF0osPUmAOq8zWhb8xBq3Me9qvExfQWSPXUAc/m5S0dQjnbju2yCO37W63cRwAiAilnKuoBiXBxtr9lnCPN5bDqA+vCpeOsXeqivQEIA5BFwnt44Wa/febrWUudCAFTMUtYFZBuGQuiO2F6zzxDm89gEQAJgubcuAmBKOV9QKU+PzXQCWa/furOrzGgCoMI56wKyDUMEQF0osPUmAOq8eQSsuPkohvrKNYXrACqMGZp/gazX7/wL8CUQ1RxlXUC2gYQAqAsktt4EQJ03AVB1+yl7MAGwbDoGBiSQ9fpdBCo6gIpZyrqAbAMJAVAXSGy9CYA6bwKg4uajGEoAVOAxNBiBrNfvIkARABWzlHUB2QaSSv9bigq6kkNtr9lnCPN5bD4DqA+fWdRvEfZJACzCLHGOWQtkvX5nff4u9k8AVChmXUC2YYgAqAsFtt4EQJ03HUDFzUcxlACowGNoMAJZr99FgCIAKmYp6wKyDSQEQF0gsfUmAOq8CYCKm49iKAFQgcfQYASyXr+LAEUAVMxS1gVkG0gIgLpAYutNANR5EwAVNx/FUAKgAo+hwQhkvX4XAYoAqJilrAvINpAQAHWBxNabAKjzJgAqbj6KoQRABR5DgxHIev0uAhQBUDFLWReQbSAhAOoCia03AVDnTQBU3HwUQwmACjyGBiOQ9fpdBCgCoGKWsi4g20BCANQFEltvAqDOmwCouPkohhIAFXgMDUYg6/W7CFAEQMUsZV1AtoGEAKgLJLbeBECdNwFQcfNRDCUAKvAYGoxA1ut3EaAIgIpZyrqAbAMJAVAXSGy9CYA6bwKg4uZTwKEl318iUldXwAvilAstkPX6XQQcAqBilrIuINtAQgDUBRJbbwKgzpsAqLj5FHAoAbCAkxbwKWe9fheBjgComKWsC8g2kBAAdYHE1psAqPMmACpuPgUcSgAs4KQFfMpZr99FoCMAKmYp6wKyDSQEQF0gsfUmAOq8CYCKm08BhxIACzhpAZ9y1ut3EegIgIpZyrqAbAMJAVAXSGy9CYA6bwKg4uZTwKEEwAJOWsCnnPX6XQQ6AqBilrIuINtAQgDUBRJbbwKgzpsAqLj5FHAoAbCAkxbwKWe9fheBjgComKWsC8g2kBAAdYHE1psAqPMmACpuPgUcSgAs4KQFfMpZr99FoCMAKmYp6wKyDSQEQF0gsfUmAOq8CYCKm08BhxIACzhpAZ9y1ut3EegIgIpZyrqAbAMJAVAXSGy9CYA6bwKg4uZTwKEEwAJOWsCnnPX6XQQ6AqBilrIuINtAQgDUBRJbbwKgzpsAqLj5FHAoAbCAkxbwKWe9fheBjgComKWsC8g2kBAAdYHE1psAqPMmACpuPgUcSgAs4KQFfMpZr99FoCMAKmYp6wKyDSQEQF0gsfUmAOq8CYCKm08BhxIACzhpAZ9y1ut3EegIgIpZyrqASt0wQ/53M4sUwgiABEDF7SO6oQTA6KY81xec9fqd64v/38kRABWzlHUBEQAbTU5NVcmZqqsp8UeWSblI4bPkNSeptM6qqm2v25V3WR3AW+yuzQqCjTMVIABmysvOLQWyXr8tT8fL5gRABXvWBUQAJABKieBLAFS8cRnqRYAA6IWdg5YQyHr9LgI8AVAxS1kXEAGQAEgAbPoGDeFzropbTqGHEgALPX3BnXzW63cRwAiAilnKuoAIgARAAiABUHGLytVQAmCupiP6k8l6/S4CMAFQMUtZFxABkABIACQAKm5RuRpKAMzVdER/Mlmv30UAJgAqZinrAiIAEgAJgARAxS0qV0MJgLmajuhPJuv1uwjABEDFLGVdQARAAiABkACouEXlaigBMFfTEf3JZL1+FwGYAKiYpawLiABIACQAEgAVt6hcDSUA5mo6oj+ZrNfvIgATABWzlHUBEQAJgARAAqDiFsVQBBAoIZD1+l0EeAKgYpayLiACIAGQAEgAVNyiGIoAAgTAkjVAAFS8PQiACrwSQ23/VQqzG1f/MkWRjs0PQbuvPfaIAALxCGS9fhdBkgComKWsC4gOIB1AOoB0ABW3KIYigAAdQDqAWbwLCIDuVYvUhfPZfaQD6L722CMCCMQjkPX6XQRJOoCKWcq6gOgA0gGkA0gHUHGLYigCCNABpAOYxbuAAOhelQ5gM9OaqlaR6QC6rz32iAAC8QhkvX4XQZIOoGKWsi4gOoB0AOkA0gFU3KIYigACdADpAGbxLiAAulelA0gHMBEo1fm8pc590bFHBBCITiDr9bsIoHQAFbOUdQHRAaQDSAeQDqDiFsVQBBCgA0gHMIt3AQHQvSodQDqAdADdv6/YIwIINBXIev0ugjcdQMUsZV1AdADpANIBpAOouEUxFAEE6ADSAcziXUAAdK9KB5AOIB1A9+8r9ogAAnQAm9dAEB3Ajz76SK688kp56KGHkus7/fTT5Y477pBOnTq1WvOfffaZ3HTTTfLoo4/K66+/Lh07dpThw4fLbbfdJp07d079PiEApqZKvSEBkABIAEz9dmFDBBAoUyDr9bvM06rosCAC4KmnnipbtmyRefPmJXgXX3yxHHbYYfLwww+3irljxw4566yz5KKLLpKjjz5aTICcMGGCfP755/Liiy+mnoCsC4hHwI2mosS3Qs0W/FvAzUq2zu6bsrah25W3OWvrY/Mt4NT3JzZEAIHSAlmv30WwL3wAXL9+vfTq1Uuee+456d+/f2Ju/vfAgQNlw4YNcuSRR6aahxdeeEGOO+44eeONN6Rr166pxmRdQARAAiCfAWz6VqwjAKa6N7ERAgjsWSDr9bsI/oUPgHfddZdcffXVsn379ibe5vHvjBkzZNy4canm4cknn5STTjop2U+HDh1aHbNz504x/9W/TAFVV1eL6SiWGpPq4CU2IgASAAmABEDNPYSxCCDQugABUKTwAXDKlCmyaNEi2bRpU5NZ7tGjRxL+Jk6c2Gb9f/rppzJkyBA56qij5O677y65fU1NjUyaNKnFnxMA2yROvYHtI0GzY1ePJIt0bP4puNQlxYYIIIBACwECYI4DYKmw1XgWzWPbJ554QhYvXiwbN25sMsHdu3eXCy64QK6//vo9lr75QsjZZ58tb775pqxYsWKPnTw6gNnfRYoUwnyGTwJg9rXIERBAIFwBAmCOA+D7778v5r89vcwXPe65556yHwGb8Dd69Ojkm8BPPfWUHHDAAVbVnnUB8Qi40XTwJZAmtUkAtHqrsjECCCDQRCDr9bsI3IV/BFz/JZDnn38++RKHeZn/PWDAgD1+CaQ+/L366qvy9NNPy4EHHmg9X1kXEAGQABjrZwAtv8hs/d5lAAIIxC2Q9fpdBN3CB0CDbH4Gpra2VubOnZuYm5+B6datW5OfgTGf75s6daqMGjUq+bmXM888U15++WV55JFH5OCDD26Yq/3331/23nvvVHOXdQERAAmABMBUb0U2QgABBKwEsl6/rU7G08ZBBMAPP/ywxQ9B33nnnU1+CLqqqkoWLlwoY8eOlc2bN8vhhx/eKrnpBp5wwgmppiPrAiIAEgBDD4Cp3mhshAACCDgWyHr9dny6mewuiACYiUyKnWZdQARAAiABMMUbkU0QQAABS4Gs12/L0/GyOQFQwU4BKfBKDOVbwM1gSnz5JZQvgbivIPaIAAIItC3A+p3jbwG3PX3+t6CA3M8BAZAA6L6q2CMCCCDQVID1mwCoek9QQCq+VgcTAAmA7quKPSKAAAIEwOY1wCNgxbuCAKjA4xFwEwHrz3uWTMrmn0aps5oY29Dt6l9esTpJNkYAAQQcCrB+0wFUlRMFpOKjA9hIgADovpbYIwIIIFBKgPWbAKh6d1BAKj4CIAHQfQGxRwQQQCCFAOs3ATBFmZTehAJS8bkLgLfYPfIsdda2j0LNflw9DqUD6L6W2CMCCCBAB7B0DfAZQMX7gwCowCsxtKwQRgBsqslnAN0XJntEAIGgBFi/6QCqCpoCUvHRAeQRsPsCYo8IIIBACgHWbwJgijLhEbAKyXIwHUBVM89S+/83tzV39di7rJNlEAIIIOBAgABIAFSVEQWk4qMDqOkAOqQnADrEZFcIIFAIAdZvAqCqUCkgFR8BkADovoDYIwIIIJBCgPWbAJiiTEpvQgGp+AiABED3BcQeEUAAgRQCrN8EwBRlQgBUIVkOtn0caXZfF+O3gC1d97S5rTmfAXSIz64QQMCLAAGQAKgqPApIxUcHkA6g+wJijwgggEAKAdZvAmCKMqEDqEKyHGzbjaIDaAncyua25nQA9ebsAQEE/AoQAAmAqgqkgFR8dADpALovIPaIAAIIpBBg/SYApigTOoAqJMvBtt0oOoCWwHQA9WDsAQEECi9AACQAqoqYAlLx0QGkA+i+gNgjAgggkEKA9ZsAmKJM6ACqkCwHl+oAWv7ztpZH/f/Ny+o+1pQ4lOUJF+m6+QxgWeXFIAQQyJEAAZAAqCpHCkjFZ9UBtMxTZZ0YAbAZW01Vq44EwLLKi0EIIJAjAdZvAqCqHCkgFR8BsJEAHUD3tcQeEUAAgVICrN8EQNW7gwJS8REACYDuC4g9IoAAAikEWL8JgCnKpPQmFJCKjwBIAHRfQOwRAQQQSCHA+k0ATFEmBEAVkuXgIj0KNZfm6vNwRbpuV9dsWRpsjgACCDgTIAASAFXFRAGp+OgA0gF0X0DsEQEEEEghwPpNAExRJnQAVUiWg4vUCaMD2GxyK/FVbct6YnMEEECgNQECIAFQ9c6ggFR8dADpALovIPaIAAIIpBBg/SYApigTOoAqJMvBdACbglWiqWb7+4d8BtCyqNkcAQRyJ0AAJACqipICUvHRAaQD6L6A2CMCCCCQQoD1mwCYokzoAKqQLAfTAaQDaFkybI4AAghYCxAACYDWRdN4AAWk4qMDSAfQfQGxRwQQQCCFAOs3ATBFmdABVCFZDqYDSAfQsmTYHAEEELAWIAASAK2Lhg6giqzNwQRAAmCbRcIGCCCAgFKAAEgAVJUQBaTi4xFwzh8Bl/wGss+U7r7k2CMCCEQowPpNAFSVPQWk4svdYNufQzEX4OonUXxmKutjWw/I3VRzQgggELkA6zcBUPUWoIBUfLkbTABM+fiZAJi72uWEEEDAToD1mwBoVzHNtqaAVHy5G0wAJADmrig5IQQQyESA9ZsAqCosCkjFl7vBBMCUATB3M8cJIYAAAnYCrN8EQLuKoQOo8sr7YAIgATDvNcr5IYCAGwECIAFQVUkUkIovd4MJgATA3BUlJ4QAApkIsH4TAFWFRQGp+HI3mABIAMxdUXJCCCCQiQDrNwFQVVgUkIovd4MJgATA3BUlJ4QAApkIsH4TAFWFRQGp+HI3mABIAMxdUXJCCCCQiQDrNwFQVVgUkIovd4MJgATA3BUlJ4QAApkIsH4TAFWFRQGp+HI3mABIAMxdUXJCCCCQiQDrNwFQVVgUkIovd4MJgATA3BUlJ4QAApkIsH4TAFWFRQGp+HI3mABIAMxdUXJCCCCQiQDrdyAB8KOPPpIrr7xSHnrooaRQTj/9dLnjjjukU6dOqQrnkksukXnz5smMGTNkwoQJqcaYjSig1FSF2JAASAAsRKFykgggoBZg/Q4kAJ566qmyZcuWJMSZ18UXXyyHHXaYPPzww20WyQMPPCA1NTXy3nvvyTXXXEMAbFMs3A0IgATAcKubK0MAgcYCBMAAAuD69eulV69e8txzz0n//v2T+TX/e+DAgbJhwwY58sgjS1b91q1bkzGPP/64nHbaaUn4owMY702iVACsq9uDSVmDWu7P0W7Kmjyfxy7rhBmEAAIIKAUIgAEEwLvuukuuvvpq2b59e5NyMI9/zSPdcePGtVomu3fvluHDh8uIESNk/PjxScewrQC4c+dOMf/Vv0wBVVdXy44dO6RDhw7KcmS4b4GyglBZgwiAvuea4yOAQNwCBMAAAuCUKVNk0aJFsmnTpibV3KNHjyT8TZw4sdUqnzp1qjz99NNJ96+qqipVADSPiidNmtRifwTAMG4kZWW5sgYRAMOoGK4CAQSKKkAAzHEALBW2GhfbCy+8IE888YQsXrxYNm7c2KQOu3fvLhdccIFcf/31LerzpZdeSh75vvzyy9K5c+fkz+kAFvVt7O68y8pyZQ0iALqbNfaEAAII2AsQAHMcAN9//30x/+3pZULbPffcY/0IeObMmcmYdu3aNez+iy++SP5v80h38+bNqaqJAkrFVJiNyspyZQ0iABamKDhRBBAIUoD1O8cBMG3F1X8J5Pnnn5fjjjsuGWb+94ABA0p+CeSDDz6Qbdu2NTnEySefLGPGjEkeG+/piyONB1FAaWcp4O0IgAFPLpeGAAKhCrB+BxAATXGan4Gpra2VuXPnJrVqfgamW7duTX4G5qijjhLzub9Ro0a1Ws9pHgE3H0gBhXprsLiuAAKgxdWyKQIIIBCEAOt3IAHwww8/bPFD0HfeeWeTH4I2X/RYuHChjB07lgAYxNs3JxdBAMzJRHAaCCCAQHoBAmAgATD9lLvdkgJy61nIvREACzltnDQCCMQtwPpNAFS9AyggFV8YgwmAYcwjV4EAAlEJsH4TAFUFTwGp+MIYTAAMYx65CgQQiEqA9ZsAqCp4CkjFF8ZgAmAY88hVIIBAVAKs3wRAVcFTQCq+MAYTAMOYR64CAQSiEmD9JgCqCp4CUvGFMZgAGMY8chUIIBCVAOs3AVBV8BSQii+MwQTAMOaRq0AAgagEWL8JgKqCp4BUfGEMJgCGMY9cBQIIRCXA+k0AVBU8BaTiC2OwowAYBgZXgQACCBRDgPWbAKiqVApIxRfGYAJgGPPIVSCAQFQCrN8EQFXBU0AqvjAGEwDDmEeuAgEEohJg/SYAqgqeAlLxhTGYABjGPHIVCCAQlQDrNwFQVfAUkIovjMEEwDDmkatAAIGoBFi/CYCqgqeAVHxhDCYAhjGPXAUCCEQlwPpNAFQVPAWk4gtjMAEwjHnkKhBAICoB1m8CoKrgKSAVXxiDCYBhzCNXgQACUQmwfhMAVQVPAan4whhMAAxjHrkKBBCISoD1mwCoKngKSMUXxmACYBjzyFUggEBUAqzfBEBVwVNAKr4wBhMAw5hHrgIBBKISYP0mAKoKngJS8YUxmAAYxjxyFQggEJUA6zcBUFXwFJCKL4zBBMAw5pGrQACBqARYvwmAqoKngFR8YQwmAIYxj1wFAghEJcD6TQBUFTwFpOILYzABMIx55CoQQCAqAdZvAqCq4CkgFV8YgwmAYcwjV4EAAlEJsH4TAFUFTwGp+MIYTAAMYx65CgQQiEqA9ZsAqCp4CkjFF8ZgAmAY88hVIIBAVAKs3wRAVcFTQCq+MAYTAMOYR64CAQSiEmD9JgCqCp4CUvExGAEEEEAAAS8CrN8EQFXhUUAqPgYjgAACCCDgRYD1mwCoKjwKSMXHYAQQQAABBLwIsH4TAFWFRwGp+BiMAAIIIICAFwHWbwKgqvAoIBUfgxFAAAEEEPAiwPpNAFQVHgWk4mMwAggggAACXgRYvwmAqsKjgFR8DEYAAQQQQMCLAOs3AVBVeBSQio/BCCCAAAIIeBFg/SYAqgqPAlLxMRgBBBBAAAEvAqzfBEBV4VFAKj4GI4AAAggg4EWA9ZsAqCo8CkjFx2AEEEAAAQS8CLB+EwBVhUcBqfgYjAACCCCAgBcB1m8CoKrwKCAVH4MRQAABBBDwIsD6TQBUFR4FpOJjMAIIIIAAAl4EWL8JgKrCo4BUfAxGAAEEEEDAiwDrNwFQVXgUkIqPwQgggAACCHgRYP0mAKoKb8eOHdKpUyd56623pEOHDqp9MRgBBBBAAAEEKiNgAmB1dbVs375dOnbsWJmD5uwoVXV1dXU5O6fCnM6WLVuSAuKFAAIIIIAAAsUTMA2cQw89tHgn7uCMCYAKxN27d0ttba3st99+UlVVpdhTeUPr/wYTWwcyxuuO8ZrNu4LrjuvpQozzHeM15+G9bXpfH3/8sXTu3FnatWtX3iJc8FEEwAJPYKyfYYjxumO85vpFwjyeMR+3iOljFsx3PPPNXMcz13mLGwTAvM2Ixflw44jnxsFcxzPXBN+4Aj/v7bje2xZLfOabEgAzJ87uANw44rlxMNfxzDUBkACY3aqRnz3Hek/LzwzwLeA8zYX1uezcuVOmTp0qEydOlK9+9avW44s6IMbrjvGaTX1y3by3i3qfSnve1HhcNZ62LiqxHR3ASihzDAQQQAABBBBAIEcCBMAcTQanggACCCCAAAIIVEKAAFgJZY6BAAIIIIAAAgjkSIAAmKPJ4FQQQAABBBBAAIFKCBAAK6HMMRBAAAEEEEAAgRwJEABzNBk2pzJr1iyZPn26bNu2TXr37i0zZ86UoUOH2uyiUNuabzvfd999smHDBtlnn31k0KBB8stf/lKOPPLIQl2H9mSNww033CDjx49P5jzk19atW+W6666TP/3pT/Lf//5XevToIb/97W+lX79+QV72559/LjU1NfK73/1O3n77bTnkkENk7NixctNNNwX1LxX8+c9/Tu5dL730UnL/uv/++2XkyJENc2r+hYZJkybJvHnz5KOPPpL+/fvLb37zm+Q+V+TXnq77s88+S+b50Ucflddffz35t2mHDx8ut912W/IvVRT51dZ8N762Sy65JJn3GTNmyIQJE4p82YU4dwJgIaap6UkuW7ZMxowZIyYEDh48WObOnSsLFiyQdevWSdeuXQt4RW2f8imnnCLnnHOOfOc73xGzUN54443y97//Pbnmfffdt+0dBLDFCy+8IKNHj07+RYwTTzwx6ABoFv5jjjkmuc7LLrtMDjroIPnHP/4hhx12mHzrW98KYDZbXsLkyZOThW/x4sVJ2HnxxRdl3LhxcuuttyaBP5SXCfSrVq2Svn37yplnntkiAJq/2BmLRYsWJaHfXL8JERs3bkz+2c2ivvZ03eZfujnrrLPkoosukqOPPjoJviYAmXudqYMiv9qa7/pre+CBB5K/AL333ntyzTXXEAArMOkEwAoguz6E+RuxuXnOnj27Ydc9e/ZM/hZtOkQxvMxNwoSClStXyrBhw4K/5E8++SSZcxP6zYL47W9/O+gAeP311ych4Zlnngl+busv8Pvf/74cfPDBSZez/mUCUvv27WXp0qVBOph/Q71xB9B0/0zHy4Qf0/01L/M7ecbFBEPTIQrh1fy6W7sm8xe+4447Tt54441g/mJf6rpNt9+sa48//ricdtppyfzTAcy+0gmA2Rs7PcKuXbuSBWH58uUyatSohn2bDsGaNWuSQBTD67XXXpPu3bsnXcA+ffoEf8nnnXee7L///kmH6IQTTgg+APbq1UtOPvlk2bJlS1LTXbp0kcsvvzzpkIT6Mo/75syZI0888UTS+XrllVfkpJNOSoL+D3/4wyAvu3kgMI8/TYf35ZdfTjrA9a8RI0ZIp06dku5oCK80AfDJJ59M5n/79u3B/DvYrV337t27k8fdZo7NOma6/ATAylQ5AbAyzs6OUltbmyyGpjtiPgdX/5oyZUpyczSPSUJ/mS6BuVmYxyQxdIh+//vfJ10/8yjoa1/7WhQB0FyneV199dVy9tlny1//+tdkUTAfdzj33HODLHFT1+bznabTtddee8kXX3yRPAo1/9JPqK/mgWD16tXJx1pMR6jxZ98uvvjipBNmOkQhvNoKgJ9++qkMGTJEjjrqKLn77rtDuOTkGlq7bvPU6umnn07m1vw5AbBy000ArJy1kyPVB0Bzoxw4cGDDPs1CYR4TmS9JhP76yU9+In/84x/lL3/5ixx66KFBX+5bb70lxx57bNIVMp8NMq8YOoB77713ct2mzutfV155pZjHYs8++2yQc26Cvvnsk/mChPkMoOnom9D761//WkwHOMRXqQBo7nPmSzD1L9P5Ne+Fxx57LAiGPQVA84UQ85eeN998U1asqtO1wQAABL9JREFUWBFM96+1AGi+CGQe+ZqOb33gJwBWrsQJgJWzdnKk2B8BX3HFFWI+LGw+FH744Yc7Mc3zTsy1mkf9piNU/zKdIbOAtGvXLvl8VOM/y/O12Jxbt27d5Hvf+17y5ab6l/nMq+mEmu5QiK/q6moxn300f8Gpf5nrNR2gUP9ixyPgL7/9bObchD/zRS/zKPypp56SAw44IKhSbz7f5uMNpstv7mWN72/m/zbvh82bNwd1/Xm7GAJg3mYkxfmYD8uan8IwXwiof5nPTJnHoqF+CcQ8HjPhz3xg3Pyt2Hz+L4bXxx9/nDz6avwy3ww1j4bMh+RD/fzjj370o6Tj0/gR/1VXXSXPP/98k65gSDVgFnsT+My3nutf5v28cOFC2bRpU0iX2nAtpb4EYub62muvTbYzf+k1X/gK/Usg9eHv1VdfTR6JHnjggcHNefP5/uCDD5KfAmr8Mp/9Nb9yYe5zsf3MV6UnnABYaXEHx6v/GRjzgXHzGNj8btL8+fNl7dq1YjonIb7MFwDuueceefDBB5vcFMzvZZnfBYzpFcMjYPOo13zG1fwenOmImM8AmseAptZ//OMfBznd5jf/zAf/zecczSPgv/3tb2I++3b++ecn4SeUl/lGu/kSl3mZL3qYR9zm537Ml5zMz1iZa60PvuYveubzzeYvfUX/GZg9Xbd5/Gm+8W0ehT7yyCPJt57rX8bFfCSiqK+25rv5dfEIuHIzTQCsnLXTI5nu37Rp05K/PZkukPl2aMg/h2L+5tjay3RHzMIZ0yuGAGjm0yyE5gsQpiNiHvebR0UhfwvYdHt/9rOfJV3ud999N/lMlPn2780331zoAND8vWnCnAl8zV/mc47mt//qfwjaBOHGPwRd9G73nq7b/P5dqY+0mG6gec8X9dXWfBMA/c0sAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ8AAdCfPUdGAAEEEEAAAQS8CBAAvbBzUAQQQAABBBBAwJ/A/wHJTi1AJKSAkAAAAABJRU5ErkJggg==\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "non_strategic_model.normalize_weights()\n",
    "strategic_model_naive.normalize_weights()\n",
    "strategic_model_man.normalize_weights()\n",
    "\n",
    "\n",
    "print(non_strategic_model.b)\n",
    "print(strategic_model_naive.b)\n",
    "print(strategic_model_man.b)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(torch.arange(15)-0.2, non_strategic_model.w.detach(), width=0.2, color='b', align='center')\n",
    "ax.bar(torch.arange(15), strategic_model_naive.w.detach(), width=0.2, color='g', align='center')\n",
    "ax.bar(torch.arange(15)+0.2, strategic_model_man.w.detach(), width=0.2, color='r', align='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funcPred",
   "language": "python",
   "name": "funcpred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
